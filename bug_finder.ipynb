{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985464cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "166783f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "import configparser\n",
    "# import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "from typing import Dict\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce53569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266011a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8ce6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = './config.ini'\n",
    "\n",
    "if not Path(config_file_path).exists():\n",
    "    logger.warning(f\"Config file {config_file_path} not found!\")\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file_path)\n",
    "\n",
    "if 'DATABASE' not in config:\n",
    "    raise ValueError(\"DATABASE section not found in config\")\n",
    "\n",
    "db_config = {\n",
    "    'host': config['DATABASE']['host'],\n",
    "    'port': int(config['DATABASE']['port']),\n",
    "    'username': config['DATABASE']['username'],\n",
    "    'password': config['DATABASE']['password'],\n",
    "    'database': config['DATABASE']['database'],\n",
    "    'query_request': config['DATABASE']['query1'],\n",
    "    'query_assets': config['DATABASE']['query2'],\n",
    "    'query_request_with_activities': config['DATABASE']['query3'],\n",
    "    'schema': config['DATABASE']['schema']\n",
    "}\n",
    "\n",
    "db_host = db_config.get('host')\n",
    "db_port = db_config.get('port')\n",
    "db_username = db_config.get('username')\n",
    "db_password = db_config.get('password')\n",
    "db_database = db_config.get('database')\n",
    "db_query1 = db_config.get('query_request')\n",
    "db_query2 = db_config.get('query_assets')\n",
    "db_query3 = db_config.get('query_request_with_activities')\n",
    "db_schema = db_config.get('schema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d561af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def database_connector( db_type, host, port, database, username, password, **kwargs):\n",
    "    \n",
    "        encoded_password = urllib.parse.quote_plus(password)\n",
    "        connection_strings = {\n",
    "            'postgresql': f\"postgresql://{username}:{encoded_password}@{host}:{port}/{database}\",\n",
    "        }\n",
    "        return connection_strings[db_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fe5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = database_connector(\n",
    "            db_type='postgresql',\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            database=db_database,\n",
    "            username=db_username,\n",
    "            password=db_password,\n",
    "            schema=db_schema\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1d2c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sync_date_time = '2025-11-01 07:00:00.000'\n",
    "# '2025-11-01 07:00:02.929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db9077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_time = pd.to_datetime(last_sync_date_time) + datetime.timedelta(days=1)\n",
    "upper_bound = pd.to_datetime(diff_time, format='mixed').strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a08ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = '2025-11-02 08:00:00.000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e846b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0edd0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Downloaded 1 rows from 'v_requests', 508863 rows from 'v_assets', and 1 rows from 'v_request_with_activities'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        engine = create_engine(conn_string)\n",
    "        \n",
    "        if not db_query1:\n",
    "            logger.warning(\"Query for v_request is missing!\")\n",
    "            \n",
    "        else:\n",
    "            db_query1 = db_query1.replace(';',f'\\nWHERE \"requestCreatedDate\" >=\\'{last_sync_date_time}\\' and \"requestCreatedDate\" <= \\'{upper_bound}\\';')\n",
    "    \n",
    "        if not db_query2:\n",
    "            logger.warning(\"Query for v_assets is missing!\")\n",
    "           \n",
    "        # else:\n",
    "        #     self.db_query2 = self.db_query2.replace(';',f'\\nWHERE \"requestCreatedDate\" >=\\'{self.last_sync_date_time}\\';')\n",
    "        \n",
    "        if not db_query3:\n",
    "            logger.warning(\"Query for v_request_with_activities is missing!\")\n",
    "            \n",
    "        else:\n",
    "            db_query3 = db_query3.replace(';',f'\\nWHERE \"requestCreatedDate\" >=\\'{last_sync_date_time}\\' and \"requestCreatedDate\" <= \\'{upper_bound}\\';')\n",
    "\n",
    "        # print(self.db_query1)\n",
    "        # print(self.db_query2)\n",
    "        # print(self.db_query3)\n",
    "\n",
    "        df_request = pd.read_sql(db_query1, engine)\n",
    "        df_assets = pd.read_sql(db_query2, engine)\n",
    "        # df_assets = pd.read_csv('./fetched_data/v_assets.csv')\n",
    "        df_request_with_activities = pd.read_sql(db_query3, engine)\n",
    "        \n",
    "        logger.info(f\" Downloaded {len(df_request)} rows from 'v_requests', {len(df_assets)} rows from 'v_assets', and {len(df_request_with_activities)} rows from 'v_request_with_activities'.\")\n",
    "        \n",
    "        # Saving the data (Don't save when pushing incrementally!!)\n",
    "        # # self.df_request.to_csv(f\"{target_dir_path}/v_requests.csv\",index=False)\n",
    "        # # self.df_assets.to_csv(f\"{target_dir_path}/v_assets.csv\",index=False)\n",
    "        # # self.df_request_with_activities.to_csv(f\"{target_dir_path}/v_requests_with_activities.csv\",index=False)\n",
    "        \n",
    "        # logger.info(f\"Data exported to {target_dir_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.warning(f\"Error connecting to database: {e}\")\n",
    "    \n",
    "\n",
    "finally:\n",
    "    if 'engine' in locals():\n",
    "            engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36463790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestId</th>\n",
       "      <th>requestAlternateId</th>\n",
       "      <th>workType</th>\n",
       "      <th>requestDescription</th>\n",
       "      <th>requestCreatedDate</th>\n",
       "      <th>requestTargetCompletionDate</th>\n",
       "      <th>requestCompletionDate</th>\n",
       "      <th>serviceClassificationId</th>\n",
       "      <th>serviceClassificationAlternateId</th>\n",
       "      <th>serviceClassificationPath</th>\n",
       "      <th>...</th>\n",
       "      <th>locationAlternateId</th>\n",
       "      <th>locationPath</th>\n",
       "      <th>assetId</th>\n",
       "      <th>assetAlternateId</th>\n",
       "      <th>assetDescription</th>\n",
       "      <th>completionNotes</th>\n",
       "      <th>customer</th>\n",
       "      <th>country</th>\n",
       "      <th>isSelfAssign</th>\n",
       "      <th>priorityCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b71e6dbd-4a3f-41f2-ad82-1174c7f8c5b7</td>\n",
       "      <td>RRBC100309</td>\n",
       "      <td>Proactive</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>2025-11-01 16:12:15.788</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6d4a97a7-f1e4-4c1c-b37a-46a9c8cf35ee</td>\n",
       "      <td>SCRBC100235</td>\n",
       "      <td>Cleaning Services | Carpet Cleaning | Carpet -...</td>\n",
       "      <td>...</td>\n",
       "      <td>LUS508405</td>\n",
       "      <td>US, AZ, Peoria / RBC-AZ001DR, Peoria-Sun City ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Royal Bank of Canada</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              requestId requestAlternateId   workType  \\\n",
       "0  b71e6dbd-4a3f-41f2-ad82-1174c7f8c5b7         RRBC100309  Proactive   \n",
       "\n",
       "  requestDescription      requestCreatedDate requestTargetCompletionDate  \\\n",
       "0            TESTING 2025-11-01 16:12:15.788                        None   \n",
       "\n",
       "  requestCompletionDate               serviceClassificationId  \\\n",
       "0                  None  6d4a97a7-f1e4-4c1c-b37a-46a9c8cf35ee   \n",
       "\n",
       "  serviceClassificationAlternateId  \\\n",
       "0                      SCRBC100235   \n",
       "\n",
       "                           serviceClassificationPath  ... locationAlternateId  \\\n",
       "0  Cleaning Services | Carpet Cleaning | Carpet -...  ...           LUS508405   \n",
       "\n",
       "                                        locationPath assetId assetAlternateId  \\\n",
       "0  US, AZ, Peoria / RBC-AZ001DR, Peoria-Sun City ...    None             None   \n",
       "\n",
       "  assetDescription completionNotes              customer country isSelfAssign  \\\n",
       "0             None            None  Royal Bank of Canada      US        False   \n",
       "\n",
       "   priorityCode  \n",
       "0          None  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9bb5b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestId</th>\n",
       "      <th>requestAlternateId</th>\n",
       "      <th>workType</th>\n",
       "      <th>requestDescription</th>\n",
       "      <th>requestCreatedDate</th>\n",
       "      <th>requestTargetCompletionDate</th>\n",
       "      <th>requestCompletionDate</th>\n",
       "      <th>activityId</th>\n",
       "      <th>activityAlternateId</th>\n",
       "      <th>activityDescription</th>\n",
       "      <th>activityStartDate</th>\n",
       "      <th>activityCompletionDate</th>\n",
       "      <th>completionNotes</th>\n",
       "      <th>providertype</th>\n",
       "      <th>customer</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b71e6dbd-4a3f-41f2-ad82-1174c7f8c5b7</td>\n",
       "      <td>RRBC100309</td>\n",
       "      <td>Proactive</td>\n",
       "      <td>TESTING</td>\n",
       "      <td>2025-11-01 16:12:15.788</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Royal Bank of Canada</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              requestId requestAlternateId   workType  \\\n",
       "0  b71e6dbd-4a3f-41f2-ad82-1174c7f8c5b7         RRBC100309  Proactive   \n",
       "\n",
       "  requestDescription      requestCreatedDate requestTargetCompletionDate  \\\n",
       "0            TESTING 2025-11-01 16:12:15.788                        None   \n",
       "\n",
       "  requestCompletionDate activityId activityAlternateId activityDescription  \\\n",
       "0                  None       None                None                None   \n",
       "\n",
       "  activityStartDate activityCompletionDate completionNotes providertype  \\\n",
       "0              None                   None            None         None   \n",
       "\n",
       "               customer country  \n",
       "0  Royal Bank of Canada      US  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_request_with_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc6dfcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_hvac_df_ = pd.read_csv('./data/hvac_assets/IFM_Assets_RuleBasedEngineResults(IFM_Assets_RuleBasedEngineResul).csv')\n",
    "suggested_asset_df = pd.read_csv('./data/asset_suggest_data/asset_suggest_model.csv')\n",
    "vendor_data = pd.read_csv('./data/asset_vendor/request_act_vendor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Error preprocessing data: cannot set a frame with no defined index and a scalar\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/r2/5_8vrrd90lsdfnwbdxcdvqxw0000gp/T/ipykernel_79002/18777002.py\", line 20, in <module>\n",
      "    v_assets_with_hvac.loc[v_assets_with_hvac['is_HVAC'] == True, 'asset_type'] = 'HVAC'\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/pandas/core/indexing.py\", line 912, in __setitem__\n",
      "    iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/pandas/core/indexing.py\", line 1848, in _setitem_with_indexer\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: cannot set a frame with no defined index and a scalar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\x9b\\x04\\x81i?\\xa1.\\xb7\\xfb\\xa9\\x17d', b'hl\\x99Q\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6']\n",
      "Bad pipe message: %s [b'\\x16w\\xf2\\xff\\xeb.ZDW7s\\x8e\\xec\\x8e\\xf2I\\xc9\\x85\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00']\n",
      "Bad pipe message: %s [b\"\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04\\x13\\x05\\xc0\\x01\\xc0\\x02\\xc0\\x03\\xc0\\x04\\xc0\\x05\\xc0\\x06\\xc0\\x07\\xc0\\x08\\xc0\\t\\xc0\\n\\xc0\\x0b\\xc0\\x0c\\xc0\\r\\xc0\\x0e\\xc0\\x0f\\xc0\\x10\\xc0\\x11\\xc0\\x12\\xc0\\x13\\xc0\\x14\\xc0\\x15\\xc0\\x16\\xc0\\x17\\xc0\\x18\\xc0\\x19\\xc0#\\xc0$\\xc0%\\xc0&\\xc0'\\xc0(\\xc0)\\xc0*\\xc0+\\xc0,\\xc0-\\xc0.\\xc0/\\xc00\\xc01\\xc02\\xc0r\\xc0s\\xc0t\\xc0u\\xc0v\\xc0w\\xc0x\\xc0y\\xc0z\\xc0{\\xc0|\\xc0}\\xc0~\\xc0\\x7f\\xc0\\x80\\xc0\\x81\\xc0\\x82\\xc0\\x83\"]\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n"
     ]
    }
   ],
   "source": [
    "# def data_preprocessor(self):\n",
    "try:\n",
    "    # Activity:\n",
    "    activity_df = df_request_with_activities[df_request_with_activities['activityAlternateId'].notna()][['providertype','activityAlternateId','activityDescription']]\n",
    "    activity_df.drop_duplicates(inplace = True)\n",
    "\n",
    "    # Asset:\n",
    "    requests_subset = df_request[['requestId','assetAlternateId', 'requestAlternateId']]\n",
    "    requests_subset = requests_subset[requests_subset.assetAlternateId.notna()]\n",
    "\n",
    "    v_assets = df_assets[['assetId','Asset Alt Id', 'Asset Description', 'manufacturer', 'model', 'serialNumber']]\n",
    "    v_assets = v_assets.merge(requests_subset, left_on = 'Asset Alt Id', right_on = 'assetAlternateId', how= 'left')\n",
    "    v_assets = v_assets[v_assets['requestAlternateId'].notna()] # keeping only those asset records which are associated to the presently fetched serviceRequests\n",
    "\n",
    "    is_hvac_df = is_hvac_df_.copy()\n",
    "    is_hvac_df['is_HVAC'] = True\n",
    "    is_hvac_df.drop(columns=['Asset Description'], inplace = True)\n",
    "    v_assets_with_hvac = v_assets.merge(is_hvac_df, on='Asset Alt Id', how='left')\n",
    "\n",
    "    v_assets_with_hvac.loc[v_assets_with_hvac['is_HVAC'] == True, 'asset_type'] = 'HVAC'\n",
    "\n",
    "    final_assets_df = v_assets_with_hvac[['assetId', 'Asset Description', 'Asset Alt Id', 'manufacturer', 'model',\n",
    "                                            'serialNumber', 'is_HVAC', 'asset_type', 'requestId','assetAlternateId', 'requestAlternateId']]\n",
    "    final_assets_df.loc[:, 'is_HVAC'] = final_assets_df['is_HVAC'].fillna(False)\n",
    "\n",
    "    suggested_asset_df = suggested_asset_df.copy()\n",
    "    suggested_asset_df.rename(columns={'asset_id': 'suggested_asset'}, inplace=True)\n",
    "    suggested_asset_df_subset = suggested_asset_df[['request_id', 'suggested_asset']]\n",
    "\n",
    "    final_assets_df = final_assets_df.merge(suggested_asset_df_subset, left_on = 'requestId', right_on = 'request_id', how = 'left')\n",
    "    final_assets_df = final_assets_df[['assetId', 'Asset Description', 'Asset Alt Id', 'manufacturer', 'model',\n",
    "                                        'serialNumber', 'is_HVAC', 'asset_type', 'suggested_asset','requestAlternateId']]\n",
    "\n",
    "    vendor_data = vendor_data.copy()\n",
    "    vendor_data = vendor_data[['requestAlternateId','vendorName', 'vendorAddress1', 'vendorCity',\n",
    "                        'vendorRegion', 'vendorCountry', 'vendorPostalCode']]\n",
    "    assets_with_vendors = final_assets_df.merge(vendor_data, on = 'requestAlternateId', how = 'left')\n",
    "    assets_df = assets_with_vendors[['Asset Description', 'Asset Alt Id', 'manufacturer', 'model','serialNumber', \n",
    "                                                'is_HVAC', 'asset_type', 'suggested_asset','vendorName', 'vendorAddress1', 'vendorCity',\n",
    "                                                'vendorRegion', 'vendorCountry', 'vendorPostalCode']]\n",
    "\n",
    "    # Country:\n",
    "    country_df = df_request[['country']].drop_duplicates()\n",
    "\n",
    "    # Customer:\n",
    "    customer_df = df_request[['customer']].drop_duplicates()\n",
    "\n",
    "    # Location:\n",
    "    location_df = df_request[['locationAlternateId', 'locationPath']].drop_duplicates()\n",
    "\n",
    "    # Service Requests:\n",
    "    temp_ser_req = df_request[['isSelfAssign', 'priorityCode', \n",
    "                'requestCreatedDate', 'requestDescription', 'requestAlternateId', 'completionNotes', \n",
    "                'requestTargetCompletionDate', 'serviceClassificationAlternateId', 'serviceClassificationPath',  \n",
    "                'requestCompletionDate', 'workType']]\n",
    "\n",
    "    def to_local_datetime(date_col):\n",
    "\n",
    "        if date_col is None:\n",
    "            return None\n",
    "        \n",
    "        if date_col.isna().all():\n",
    "            return date_col\n",
    "        \n",
    "        dt_series = pd.to_datetime(date_col, format='mixed')\n",
    "        formatted = dt_series.dt.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]\n",
    "        \n",
    "        return formatted.str.replace(' ', 'T')\n",
    "\n",
    "\n",
    "    def process_service_requests(df_service_request):\n",
    "            \n",
    "            date_cols = ['requestCreatedDate', 'requestTargetCompletionDate', 'requestCompletionDate']\n",
    "            \n",
    "            for col in date_cols:\n",
    "                if col in df_service_request.columns:\n",
    "                    df_service_request.loc[:, col] = to_local_datetime(df_service_request[col])\n",
    "            \n",
    "            df_service_request['createdYear'] = pd.to_datetime(df_service_request['requestCreatedDate']).dt.year\n",
    "            df_service_request['createdMonth'] = pd.to_datetime(df_service_request['requestCreatedDate']).dt.month\n",
    "                \n",
    "            df_service_request['isCompleted'] = df_service_request['requestCompletionDate'].notna()\n",
    "            \n",
    "            conditions = [\n",
    "                df_service_request['requestCompletionDate'].isna(),\n",
    "                df_service_request['requestTargetCompletionDate'].isna(),\n",
    "                df_service_request['requestCompletionDate'] <= df_service_request['requestTargetCompletionDate'],\n",
    "                df_service_request['requestCompletionDate'] > df_service_request['requestTargetCompletionDate']\n",
    "            ]\n",
    "            \n",
    "            choices = ['Open', 'Open', 'Met', 'Miss']\n",
    "            \n",
    "            df_service_request['sla'] = np.select(conditions, choices, default='Unknown')\n",
    "            \n",
    "            return df_service_request\n",
    "\n",
    "\n",
    "    service_req_df = process_service_requests(temp_ser_req)\n",
    "\n",
    "    activity_df = activity_df.copy()\n",
    "    assets_df = assets_df.copy()\n",
    "    country_df = country_df.copy()\n",
    "    customer_df = customer_df.copy()\n",
    "    location_df = location_df.copy()\n",
    "    service_req_df = service_req_df.copy()\n",
    "    logger.info(\"Node and Property data prepared!\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Error preprocessing data: {e}\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80adc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # renaming the features:\n",
    "    activity_df.rename(columns={'activityAlternateId': 'activityId', 'providertype':'providerType'}, inplace=True)\n",
    "\n",
    "    assets_df.rename(columns={'Asset Alt Id': 'assetId', 'Asset Description':'assetDescription', 'vendorAddress1':'vendorAddress'}, inplace=True)\n",
    "\n",
    "    location_df.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "\n",
    "    service_req_df.rename(columns={'requestAlternateId': 'requestId', 'serviceClassificationAlternateId': 'serviceClassificationId'}, inplace=True)\n",
    "\n",
    "    # logger.info(f\"Data for migration to Neo4J is saved on path: {neo4j_dir_path} and ready to be imported!\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Error Renaming Features: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b34431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>providerType</th>\n",
       "      <th>activityId</th>\n",
       "      <th>activityDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>AC557088</td>\n",
       "      <td>HVAC | General - Knight Cancer Research Buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TECHNICIAN</td>\n",
       "      <td>AC557890</td>\n",
       "      <td>Plumbing | Pipefitting - STFTNMU1 | RSM-08.4-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>AC553975</td>\n",
       "      <td>General Building | Structural &amp; Roofing - Roof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>AC558680</td>\n",
       "      <td>Fire Life Safety | Fire Extinguishers - One Jn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISPATCHSITE</td>\n",
       "      <td>AC558704</td>\n",
       "      <td>HVAC | General - Split System Quarterly  | AIR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9811</th>\n",
       "      <td>TECHNICIAN</td>\n",
       "      <td>AC560109</td>\n",
       "      <td>Fire Life Safety | Fire Protection - 052310-40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9812</th>\n",
       "      <td>None</td>\n",
       "      <td>AC556335</td>\n",
       "      <td>HVAC | General - Pump, Condensate - Quarterly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813</th>\n",
       "      <td>TECHNICIAN</td>\n",
       "      <td>AC555114</td>\n",
       "      <td>General Building | Building Services - TX576 |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>TECHNICIAN</td>\n",
       "      <td>AC557863</td>\n",
       "      <td>HVAC | General - Heater (Gas) PM | Heater, Uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9816</th>\n",
       "      <td>TECHNICIAN</td>\n",
       "      <td>AC558155</td>\n",
       "      <td>General Mechanical | General - NH001 | Tank, A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9230 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      providerType activityId  \\\n",
       "0             None   AC557088   \n",
       "1       TECHNICIAN   AC557890   \n",
       "2             None   AC553975   \n",
       "3             None   AC558680   \n",
       "4     DISPATCHSITE   AC558704   \n",
       "...            ...        ...   \n",
       "9811    TECHNICIAN   AC560109   \n",
       "9812          None   AC556335   \n",
       "9813    TECHNICIAN   AC555114   \n",
       "9814    TECHNICIAN   AC557863   \n",
       "9816    TECHNICIAN   AC558155   \n",
       "\n",
       "                                    activityDescription  \n",
       "0     HVAC | General - Knight Cancer Research Buildi...  \n",
       "1     Plumbing | Pipefitting - STFTNMU1 | RSM-08.4-0...  \n",
       "2     General Building | Structural & Roofing - Roof...  \n",
       "3     Fire Life Safety | Fire Extinguishers - One Jn...  \n",
       "4     HVAC | General - Split System Quarterly  | AIR...  \n",
       "...                                                 ...  \n",
       "9811  Fire Life Safety | Fire Protection - 052310-40...  \n",
       "9812  HVAC | General - Pump, Condensate - Quarterly ...  \n",
       "9813  General Building | Building Services - TX576 |...  \n",
       "9814  HVAC | General - Heater (Gas) PM | Heater, Uni...  \n",
       "9816  General Mechanical | General - NH001 | Tank, A...  \n",
       "\n",
       "[9230 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a1ceea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Relationships created!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    LOCATED_AT = df_request[['assetAlternateId','locationAlternateId']].dropna().drop_duplicates()\n",
    "    LOCATED_AT.rename(columns={'assetAlternateId': 'assetId', 'locationAlternateId': 'locationId'}, inplace=True)\n",
    "    # self.LOCATED_AT.to_csv(f\"{neo4j_relationship_dir_path}/LOCATED_AT.csv\",index=False)\n",
    "\n",
    "    AT_LOCATION = df_request[['requestAlternateId','locationAlternateId']].dropna().drop_duplicates()\n",
    "    AT_LOCATION.rename(columns={'requestAlternateId': 'requestId', 'locationAlternateId': 'locationId'}, inplace=True)\n",
    "    # self.AT_LOCATION.to_csv(f\"{neo4j_relationship_dir_path}/AT_LOCATION.csv\",index=False)\n",
    "\n",
    "    HAS_ACTIVITY = df_request_with_activities[['activityAlternateId', 'requestAlternateId']].dropna().drop_duplicates()\n",
    "    HAS_ACTIVITY.rename(columns={'requestAlternateId': 'requestId', 'activityAlternateId': 'activityId'}, inplace=True)\n",
    "    # self.HAS_ACTIVITY.to_csv(f\"{neo4j_relationship_dir_path}/HAS_ACTIVITY.csv\",index=False)\n",
    "\n",
    "    FOR_ASSET = df_request[['requestAlternateId','assetAlternateId']].dropna().drop_duplicates()\n",
    "    FOR_ASSET.rename(columns={'requestAlternateId': 'requestId', 'assetAlternateId': 'assetId'}, inplace=True)\n",
    "    # self.FOR_ASSET.to_csv(f\"{neo4j_relationship_dir_path}/FOR_ASSET.csv\",index=False)\n",
    "\n",
    "    OPERATES_IN = df_request[['customer','country']].dropna().drop_duplicates()\n",
    "    # self.OPERATES_IN.to_csv(f\"{neo4j_relationship_dir_path}/OPERATES_IN.csv\",index=False)\n",
    "\n",
    "    RESIDES_AT = df_request[['customer','locationAlternateId']].dropna().drop_duplicates()\n",
    "    RESIDES_AT.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "    # self.RESIDES_AT.to_csv(f\"{neo4j_relationship_dir_path}/RESIDES_AT.csv\",index=False)\n",
    "\n",
    "    OWNS = df_request[['customer','assetAlternateId']].dropna().drop_duplicates()\n",
    "    OWNS.rename(columns={'assetAlternateId': 'assetId'}, inplace=True)\n",
    "    # self.OWNS.to_csv(f\"{neo4j_relationship_dir_path}/OWNS.csv\",index=False)\n",
    "\n",
    "    CREATES = df_request[['customer','requestAlternateId']].dropna().drop_duplicates()\n",
    "    CREATES.rename(columns={'requestAlternateId': 'requestId'}, inplace=True)\n",
    "    # self.CREATES.to_csv(f\"{neo4j_relationship_dir_path}/CREATES.csv\",index=False)\n",
    "\n",
    "    IN = df_request[['country','locationAlternateId']].dropna().drop_duplicates()\n",
    "    IN.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "    # self.IN.to_csv(f\"{neo4j_relationship_dir_path}/IN.csv\",index=False)\n",
    "\n",
    "    logger.info(f\"Relationships created!\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Error while creating and saving relationships: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4d03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestId</th>\n",
       "      <th>assetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROHS101050</td>\n",
       "      <td>AUS434275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RSTF129401</td>\n",
       "      <td>AUS303002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RJNJ122478</td>\n",
       "      <td>ACO100054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RMFG121180</td>\n",
       "      <td>AUS408425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RCHR249629</td>\n",
       "      <td>AUS330504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>RALK116010</td>\n",
       "      <td>AUS286004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8861</th>\n",
       "      <td>RCHR247411</td>\n",
       "      <td>AUS314632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8862</th>\n",
       "      <td>RSTF129381</td>\n",
       "      <td>AUS294405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8863</th>\n",
       "      <td>RCHR249274</td>\n",
       "      <td>AUS312181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8864</th>\n",
       "      <td>RDTV123108</td>\n",
       "      <td>AUS351979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8465 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       requestId    assetId\n",
       "0     ROHS101050  AUS434275\n",
       "1     RSTF129401  AUS303002\n",
       "3     RJNJ122478  ACO100054\n",
       "4     RMFG121180  AUS408425\n",
       "5     RCHR249629  AUS330504\n",
       "...          ...        ...\n",
       "8860  RALK116010  AUS286004\n",
       "8861  RCHR247411  AUS314632\n",
       "8862  RSTF129381  AUS294405\n",
       "8863  RCHR249274  AUS312181\n",
       "8864  RDTV123108  AUS351979\n",
       "\n",
       "[8465 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOR_ASSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c061bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_injestion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
