{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "import configparser\n",
    "# import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbb622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, config_file_path):\n",
    "\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.warning(f\"Config file {config_file_path} not found!\")\n",
    "        \n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_file_path)\n",
    "\n",
    "        if 'DATABASE' not in config:\n",
    "            raise ValueError(\"DATABASE section not found in config\")\n",
    "        \n",
    "        db_config = {\n",
    "            'host': config['DATABASE']['host'],\n",
    "            'port': int(config['DATABASE']['port']),\n",
    "            'username': config['DATABASE']['username'],\n",
    "            'password': config['DATABASE']['password'],\n",
    "            'database': config['DATABASE']['database'],\n",
    "            'query_request': config['DATABASE']['query1'],\n",
    "            'query_assets': config['DATABASE']['query2'],\n",
    "            'query_request_with_activities': config['DATABASE']['query3'],\n",
    "            'schema': config['DATABASE']['schema']\n",
    "        }\n",
    "\n",
    "        self.db_host = db_config.get('host')\n",
    "        self.db_port = db_config.get('port')\n",
    "        self.db_username = db_config.get('username')\n",
    "        self.db_password = db_config.get('password')\n",
    "        self.db_database = db_config.get('database')\n",
    "        self.db_query1 = db_config.get('query_request')\n",
    "        self.db_query2 = db_config.get('query_assets')\n",
    "        self.db_query3 = db_config.get('query_request_with_activities')\n",
    "        self.db_schema = db_config.get('schema')   \n",
    "            \n",
    "    def executor(self):\n",
    "        self.conn_string = self.database_connector(\n",
    "            db_type='postgresql',\n",
    "            host=self.db_host,\n",
    "            port=self.db_port,\n",
    "            database=self.db_database,\n",
    "            username=self.db_username,\n",
    "            password=self.db_password,\n",
    "            schema=self.db_schema\n",
    "            )\n",
    "        \n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"LOADING DATA\")\n",
    "        logger.info(\"=\" * 50)\n",
    "\n",
    "        self.load_and_save_data()\n",
    "        self.load_CSVs()\n",
    "        self.data_preprocessor()\n",
    "        self.save_neo4j_CSVs()\n",
    "        self.create_and_save_relationships()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"DATA LOADING SUCCESSFUL!\")\n",
    "        logger.info(\"=\" * 50)\n",
    "\n",
    "\n",
    "    def database_connector(self, db_type, host, port, database, username, password, **kwargs):\n",
    "    \n",
    "        encoded_password = urllib.parse.quote_plus(password)\n",
    "        connection_strings = {\n",
    "            'postgresql': f\"postgresql://{username}:{encoded_password}@{host}:{port}/{database}\",\n",
    "        }\n",
    "        return connection_strings[db_type]\n",
    "\n",
    "\n",
    "    def load_and_save_data(self):\n",
    "        \n",
    "        target_dir_path = './fetched_data'\n",
    "        Path(target_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            engine = create_engine(self.conn_string)\n",
    "            \n",
    "            if not self.db_query1:\n",
    "                logger.warning(\"Query for v_request is missing!\")\n",
    "                return None \n",
    "        \n",
    "            if not self.db_query2:\n",
    "                logger.warning(\"Query for v_assets is missing!\")\n",
    "                return None\n",
    "            \n",
    "            if not self.db_query3:\n",
    "                logger.warning(\"Query for v_request_with_activities is missing!\")\n",
    "                return None\n",
    "\n",
    "            self.df_request = pd.read_sql(self.db_query1, engine)\n",
    "            self.df_assets = pd.read_sql(self.db_query2, engine)\n",
    "            self.df_request_with_activities = pd.read_sql(self.db_query3, engine)\n",
    "            \n",
    "            logger.info(f\" Downloaded {len(self.df_request)} rows from 'v_requests', {len(self.df_assets)} rows from 'v_assets', and {len(self.df_request_with_activities)} rows from 'v_request_with_activities'.\")\n",
    "            \n",
    "            self.df_request.to_csv(f\"{target_dir_path}/v_requests.csv\",index=False)\n",
    "            self.df_assets.to_csv(f\"{target_dir_path}/v_assets.csv\",index=False)\n",
    "            self.df_request_with_activities.to_csv(f\"{target_dir_path}/v_requests_with_activities.csv\",index=False)\n",
    "            \n",
    "            logger.info(f\"Data exported to {target_dir_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error connecting to database: {e}\")\n",
    "            return None\n",
    "        \n",
    "        finally:\n",
    "            if 'engine' in locals():\n",
    "                engine.dispose()\n",
    "\n",
    "    def create_and_save_relationships(self):\n",
    "\n",
    "        neo4j_relationship_dir_path = './neo4j_relationships'\n",
    "        Path(neo4j_relationship_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            self.LOCATED_AT = self.df_request[['assetAlternateId','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'assetAlternateId': 'assetId', 'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.LOCATED_AT.to_csv(f\"{neo4j_relationship_dir_path}/LOCATED_AT.csv\",index=False)\n",
    "\n",
    "            self.AT_LOCATION = self.df_request[['requestAlternateId','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'requestAlternateId': 'requestId', 'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.AT_LOCATION.to_csv(f\"{neo4j_relationship_dir_path}/AT_LOCATION.csv\",index=False)\n",
    "\n",
    "            self.HAS_ACTIVITY = self.df_request_with_activities[['activityAlternateId', 'requestAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'requestAlternateId': 'requestId', 'activityAlternateId': 'activityId'}, inplace=True)\n",
    "            self.HAS_ACTIVITY.to_csv(f\"{neo4j_relationship_dir_path}/HAS_ACTIVITY.csv\",index=False)\n",
    "\n",
    "            self.FOR_ASSET = self.df_request[['requestAlternateId','assetAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'requestAlternateId': 'requestId', 'assetAlternateId': 'assetId'}, inplace=True)\n",
    "            self.FOR_ASSET.to_csv(f\"{neo4j_relationship_dir_path}/FOR_ASSET.csv\",index=False)\n",
    "\n",
    "            self.OPERATES_IN = self.df_request[['customer','country']].dropna().drop_duplicates()\n",
    "            self.OPERATES_IN.to_csv(f\"{neo4j_relationship_dir_path}/OPERATES_IN.csv\",index=False)\n",
    "\n",
    "            self.RESIDES_AT = self.df_request[['customer','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.RESIDES_AT.to_csv(f\"{neo4j_relationship_dir_path}/RESIDES_AT.csv\",index=False)\n",
    "\n",
    "            self.OWNS = self.df_request[['customer','assetAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'assetAlternateId': 'assetId'}, inplace=True)\n",
    "            self.OWNS.to_csv(f\"{neo4j_relationship_dir_path}/OWNS.csv\",index=False)\n",
    "\n",
    "            self.CREATES = self.df_request[['customer','requestAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'requestAlternateId': 'requestId'}, inplace=True)\n",
    "            self.CREATES.to_csv(f\"{neo4j_relationship_dir_path}/CREATES.csv\",index=False)\n",
    "\n",
    "            self.IN = self.df_request[['country','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.IN.to_csv(f\"{neo4j_relationship_dir_path}/IN.csv\",index=False)\n",
    "\n",
    "            logger.info(f\"Relationships created and saved to path: {neo4j_relationship_dir_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logger.warning(f\"Error while creating and saving relationships: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    def load_CSVs(self):\n",
    "        self.is_hvac_df = pd.read_csv('./data/hvac_assets/IFM_Assets_RuleBasedEngineResults(IFM_Assets_RuleBasedEngineResul).csv')\n",
    "        self.suggested_asset_df = pd.read_csv('./data/asset_suggest_data/asset_suggest_model.csv')\n",
    "        self.vendor_data = pd.read_csv('./data/asset_vendor/request_act_vendor.csv')\n",
    "\n",
    "        logger.info(\"Helper CSV files loaded successfully.\")\n",
    "        \n",
    "    \n",
    "    def data_preprocessor(self):\n",
    "\n",
    "        # Activity:\n",
    "        activity_df = self.df_request_with_activities[self.df_request_with_activities['activityAlternateId'].notna()][['providertype','activityAlternateId','activityDescription']]\n",
    "        activity_df.drop_duplicates(inplace = True)\n",
    "\n",
    "        # Asset:\n",
    "        requests_subset = self.df_request[['requestId','assetAlternateId', 'requestAlternateId']]\n",
    "        requests_subset = requests_subset[requests_subset.assetAlternateId.notna()]\n",
    "\n",
    "        v_assets = self.df_assets[['assetId','Asset Alt Id', 'Asset Description', 'manufacturer', 'model', 'serialNumber']]\n",
    "        v_assets = v_assets.merge(requests_subset, left_on = 'Asset Alt Id', right_on = 'assetAlternateId', how= 'left')\n",
    "\n",
    "        is_hvac_df = self.is_hvac_df.copy()\n",
    "        is_hvac_df['is_HVAC'] = True\n",
    "        is_hvac_df.drop(columns=['Asset Description'], inplace = True)\n",
    "        v_assets_with_hvac = v_assets.merge(is_hvac_df, on='Asset Alt Id', how='left')\n",
    "        v_assets_with_hvac.loc[v_assets_with_hvac['is_HVAC'] == True, 'asset_type'] = 'HVAC'\n",
    "\n",
    "        final_assets_df = v_assets_with_hvac[['assetId', 'Asset Description', 'Asset Alt Id', 'manufacturer', 'model',\n",
    "                                              'serialNumber', 'is_HVAC', 'asset_type', 'requestId','assetAlternateId', 'requestAlternateId']]\n",
    "        final_assets_df.loc[:, 'is_HVAC'] = final_assets_df['is_HVAC'].fillna(False)\n",
    "\n",
    "        suggested_asset_df = self.suggested_asset_df.copy()\n",
    "        suggested_asset_df.rename(columns={'asset_id': 'suggested_asset'}, inplace=True)\n",
    "        suggested_asset_df_subset = suggested_asset_df[['request_id', 'suggested_asset']]\n",
    "\n",
    "        final_assets_df = final_assets_df.merge(suggested_asset_df_subset, left_on = 'requestId', right_on = 'request_id', how = 'left')\n",
    "        final_assets_df = final_assets_df[['assetId', 'Asset Description', 'Asset Alt Id', 'manufacturer', 'model',\n",
    "                                           'serialNumber', 'is_HVAC', 'asset_type', 'suggested_asset','requestAlternateId']]\n",
    "        \n",
    "        vendor_data = self.vendor_data.copy()\n",
    "        vendor_data = vendor_data[['requestAlternateId','vendorName', 'vendorAddress1', 'vendorCity',\n",
    "                           'vendorRegion', 'vendorCountry', 'vendorPostalCode']]\n",
    "        assets_with_vendors = final_assets_df.merge(vendor_data, on = 'requestAlternateId', how = 'left')\n",
    "        assets_df = assets_with_vendors[['Asset Description', 'Asset Alt Id', 'manufacturer', 'model','serialNumber', \n",
    "                                                   'is_HVAC', 'asset_type', 'suggested_asset','vendorName', 'vendorAddress1', 'vendorCity',\n",
    "                                                   'vendorRegion', 'vendorCountry', 'vendorPostalCode']]\n",
    "\n",
    "        # Country:\n",
    "        country_df = self.df_request[['country']].drop_duplicates()\n",
    "\n",
    "        # Customer:\n",
    "        customer_df = self.df_request[['customer']].drop_duplicates()\n",
    "\n",
    "        # Location:\n",
    "        location_df = self.df_request[['locationAlternateId', 'locationPath']].drop_duplicates()\n",
    "\n",
    "        # Service Requests:\n",
    "        temp_ser_req = self.df_request[['isSelfAssign', 'priorityCode', \n",
    "                  'requestCreatedDate', 'requestDescription', 'requestAlternateId', 'completionNotes', \n",
    "                  'requestTargetCompletionDate', 'serviceClassificationAlternateId', 'serviceClassificationPath',  \n",
    "                  'requestCompletionDate', 'workType']]\n",
    "        \n",
    "        def to_local_datetime(date_col):\n",
    "    \n",
    "            if date_col is None:\n",
    "                return None\n",
    "            \n",
    "            if date_col.isna().all():\n",
    "                return date_col\n",
    "            \n",
    "            dt_series = pd.to_datetime(date_col, format='mixed')\n",
    "            formatted = dt_series.dt.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]\n",
    "            \n",
    "            return formatted.str.replace(' ', 'T')\n",
    "\n",
    "\n",
    "        def process_service_requests(df_service_request):\n",
    "                \n",
    "                date_cols = ['requestCreatedDate', 'requestTargetCompletionDate', 'requestCompletionDate']\n",
    "                \n",
    "                for col in date_cols:\n",
    "                    if col in df_service_request.columns:\n",
    "                        df_service_request.loc[:, col] = to_local_datetime(df_service_request[col])\n",
    "                \n",
    "                \n",
    "                df_service_request['createdYear'] = pd.to_datetime(df_service_request['requestCreatedDate']).dt.year\n",
    "                df_service_request['createdMonth'] = pd.to_datetime(df_service_request['requestCreatedDate']).dt.month\n",
    "                \n",
    "                \n",
    "                df_service_request['isCompleted'] = df_service_request['requestCompletionDate'].notna()\n",
    "                \n",
    "                \n",
    "                conditions = [\n",
    "                    df_service_request['requestCompletionDate'].isna(),\n",
    "                    df_service_request['requestTargetCompletionDate'].isna(),\n",
    "                    df_service_request['requestCompletionDate'] <= df_service_request['requestTargetCompletionDate'],\n",
    "                    df_service_request['requestCompletionDate'] > df_service_request['requestTargetCompletionDate']\n",
    "                ]\n",
    "                \n",
    "                choices = ['Open', 'Open', 'Met', 'Miss']\n",
    "                \n",
    "                df_service_request['sla'] = np.select(conditions, choices, default='Unknown')\n",
    "                \n",
    "                return df_service_request\n",
    "\n",
    "        \n",
    "        service_req_df = process_service_requests(temp_ser_req)\n",
    "\n",
    "        self.activity_df = activity_df.copy()\n",
    "        self.assets_df = assets_df.copy()\n",
    "        self.country_df = country_df.copy()\n",
    "        self.customer_df = customer_df.copy()\n",
    "        self.location_df = location_df.copy()\n",
    "        self.service_req_df = service_req_df.copy()\n",
    "\n",
    "    def save_neo4j_CSVs(self):\n",
    "        neo4j_dir_path = './neo4j_data'\n",
    "        Path(neo4j_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # renaming the features:\n",
    "            self.activity_df.rename(columns={'activityAlternateId': 'activityId', 'providertype':'providerType'}, inplace=True)\n",
    "\n",
    "            self.assets_df.rename(columns={'Asset Alt Id': 'assetId', 'Asset Description':'assetDescription', 'vendorAddress1':'vendorAddress'}, inplace=True)\n",
    "\n",
    "            self.location_df.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "\n",
    "            self.service_req_df.rename(columns={'requestAlternateId': 'requestId', 'serviceClassificationAlternateId': 'serviceClassificationId'}, inplace=True)\n",
    "\n",
    "            # saving the data\n",
    "            self.activity_df.to_csv(f\"{neo4j_dir_path}/activities.csv\",index=False)\n",
    "            self.assets_df.to_csv(f\"{neo4j_dir_path}/assets.csv\",index=False)\n",
    "            self.country_df.to_csv(f\"{neo4j_dir_path}/countries.csv\",index=False)\n",
    "            self.customer_df.to_csv(f\"{neo4j_dir_path}/customers.csv\",index=False)\n",
    "            self.location_df.to_csv(f\"{neo4j_dir_path}/location.csv\",index=False)\n",
    "            self.service_req_df.to_csv(f\"{neo4j_dir_path}/service_requests.csv\",index=False)\n",
    "\n",
    "            logger.info(f\"Data for migration to Neo4J is saved on path: {neo4j_dir_path} and ready to be imported!\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error saving CSVs: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataMigrator:\n",
    "\n",
    "    def __init__(self, config_file_path):\n",
    "\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.warning(f\"Config file {config_file_path} not found!\")\n",
    "        \n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_file_path)\n",
    "\n",
    "        if 'Neo4j' not in config:\n",
    "            raise ValueError(\"Neo4j section not found in config\")\n",
    "        \n",
    "        nj_config = {\n",
    "            'url': config['Neo4j']['url'],\n",
    "            'username': config['Neo4j']['username'],\n",
    "            'password': config['Neo4j']['password']\n",
    "        }\n",
    "\n",
    "        self.nj_url = nj_config.get('url')\n",
    "        self.nj_username = nj_config.get('username')\n",
    "        self.nj_password = nj_config.get('password')\n",
    "\n",
    "        self.driver = GraphDatabase.driver(self.nj_url, auth=(self.nj_username, self.nj_password))\n",
    "        \n",
    "        self.executor()\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def clear_database(self):\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            logger.info(\"Database cleared\")\n",
    "\n",
    "    def create_constraints(self):\n",
    "        constraints = [\n",
    "            \"CREATE CONSTRAINT activity_id IF NOT EXISTS FOR (a:Activity) REQUIRE a.activityId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT asset_id IF NOT EXISTS FOR (a:Asset) REQUIRE a.assetId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT location_id IF NOT EXISTS FOR (l:Location) REQUIRE l.locationId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT request_id IF NOT EXISTS FOR (s:ServiceRequest) REQUIRE s.requestId IS UNIQUE\"\n",
    "        ]\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for constraint in constraints:\n",
    "                try:\n",
    "                    session.run(constraint)\n",
    "                    logger.info(f\"Created constraint: {constraint.split('FOR')[1].split('REQUIRE')[0].strip()}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Constraint may already exist: {e}\")\n",
    "\n",
    "\n",
    "    def create_indexes(self):\n",
    "        \n",
    "        indexes = [\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (a:Asset) ON (a.assetId)\",\n",
    "\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdYear)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.isCompleted)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdMonth)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.sla)\",\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.requestId)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.serviceClassificationId)\" ,\n",
    "\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (c:Customer) ON (c.customer)\",\n",
    "            \n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (l:Location) ON (l.locationId),\"\n",
    "\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (ac:Activity) ON (ac.activityId),\"\n",
    "\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (cn:Country) ON (cn.country)\"\n",
    "\n",
    "        ]\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for index in indexes:\n",
    "                try:\n",
    "                    session.run(index)\n",
    "                    logger.info(f\"Created index: {index}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Index may already exist: {e}\")\n",
    "\n",
    "\n",
    "    def load_nodes_from_csv(self, csv_path: str, node_label: str, id_property: str, batch_size: int = 1000):\n",
    "        \"\"\"Load nodes from CSV file in batches.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df.where(pd.notnull(df), None)  # Replace NaN with None\n",
    "        \n",
    "        total_rows = len(df)\n",
    "        logger.info(f\"Loading {total_rows} {node_label} nodes from {csv_path}\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for i in range(0, total_rows, batch_size):\n",
    "                batch = df.iloc[i:i+batch_size]\n",
    "                records = batch.to_dict('records')\n",
    "                \n",
    "                # Build Cypher query dynamically\n",
    "                query = f\"\"\"\n",
    "                UNWIND $records AS record\n",
    "                MERGE (n:{node_label} {{{id_property}: record.{id_property}}})\n",
    "                SET n += record\n",
    "                \"\"\"\n",
    "                \n",
    "                session.run(query, records=records)\n",
    "                logger.info(f\"Loaded batch {i//batch_size + 1}/{(total_rows-1)//batch_size + 1} for {node_label}\")\n",
    "        \n",
    "        logger.info(f\"Completed loading {node_label} nodes\")\n",
    "\n",
    "\n",
    "    def load_relationships_from_csv(self, csv_path: str, rel_config: Dict, batch_size: int = 1000):\n",
    "        \"\"\"\n",
    "        Load relationships from CSV file.\n",
    "        \n",
    "        rel_config example:\n",
    "        {\n",
    "            'rel_type': 'LOCATED_AT',\n",
    "            'from_label': 'Asset',\n",
    "            'from_id_col': 'assetId',\n",
    "            'from_id_prop': 'assetId',\n",
    "            'to_label': 'Location',\n",
    "            'to_id_col': 'locationId',\n",
    "            'to_id_prop': 'locationId',\n",
    "            'properties': []  # Optional: list of relationship properties\n",
    "        }\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "        \n",
    "        total_rows = len(df)\n",
    "        logger.info(f\"Loading {total_rows} {rel_config['rel_type']} relationships from {csv_path}\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for i in range(0, total_rows, batch_size):\n",
    "                batch = df.iloc[i:i+batch_size]\n",
    "                records = batch.to_dict('records')\n",
    "                \n",
    "                # Build relationship properties string if any\n",
    "                rel_props = \"\"\n",
    "                if rel_config.get('properties'):\n",
    "                    props_str = \", \".join([f\"{p}: record.{p}\" for p in rel_config['properties']])\n",
    "                    rel_props = f\" {{{props_str}}}\"\n",
    "                \n",
    "                query = f\"\"\"\n",
    "                UNWIND $records AS record\n",
    "                MATCH (from:{rel_config['from_label']} {{{rel_config['from_id_prop']}: record.{rel_config['from_id_col']}}})\n",
    "                MATCH (to:{rel_config['to_label']} {{{rel_config['to_id_prop']}: record.{rel_config['to_id_col']}}})\n",
    "                MERGE (from)-[r:{rel_config['rel_type']}]->(to)\n",
    "                \"\"\"\n",
    "                \n",
    "                if rel_props:\n",
    "                    query += f\"\\nSET r += {{{', '.join([f'{p}: record.{p}' for p in rel_config['properties']])}}}\"\n",
    "                \n",
    "                session.run(query, records=records)\n",
    "                logger.info(f\"Loaded batch {i//batch_size + 1}/{(total_rows-1)//batch_size + 1} for {rel_config['rel_type']}\")\n",
    "        \n",
    "        logger.info(f\"Completed loading {rel_config['rel_type']} relationships\")\n",
    "    \n",
    "\n",
    "    def verify_load(self):\n",
    "        \"\"\"Verify the data load by counting nodes and relationships.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Count nodes\n",
    "            node_labels = ['Activity', 'Asset', 'Country', 'Customer', 'Location', 'ServiceRequest']\n",
    "            for label in node_labels:\n",
    "                result = session.run(f\"MATCH (n:{label}) RETURN count(n) as count\")\n",
    "                count = result.single()['count']\n",
    "                logger.info(f\"{label} nodes: {count}\")\n",
    "            \n",
    "            # Count relationships\n",
    "            result = session.run(\"MATCH ()-[r]->() RETURN type(r) as type, count(r) as count\")\n",
    "            for record in result:\n",
    "                logger.info(f\"{record['type']} relationships: {record['count']}\")\n",
    "\n",
    "    \n",
    "    def executor(self):\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"LOADING NODES\")\n",
    "        logger.info(\"=\" * 50)        \n",
    "        self.load_nodes()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"LOADING RELATIONSHIPS\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        self.load_relationships()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"VERIFYING NODE AND RELATIONSHP CREATION.\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        self.verify_load()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"DATA MIGRATION SUCCESSFUL!\")\n",
    "        logger.info(\"=\" * 50)\n",
    "\n",
    "        self.close()\n",
    "\n",
    "    \n",
    "    def load_nodes(self):\n",
    "        \n",
    "        DATA_DIR = Path(\"./neo4j_data\")\n",
    "\n",
    "        try:\n",
    "            # Optional: Clear existing data\n",
    "            # loader.clear_database()\n",
    "            \n",
    "            # Create constraints and indexes\n",
    "            self.create_constraints()\n",
    "            self.create_indexes()\n",
    "            \n",
    "            # Load nodes\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/activities.csv\", \n",
    "                \"Activity\", \n",
    "                \"activityId\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/assets.csv\", \n",
    "                \"Asset\", \n",
    "                \"assetId\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/countries.csv\", \n",
    "                \"Country\", \n",
    "                \"country\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/customers.csv\", \n",
    "                \"Customer\", \n",
    "                \"customer\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/location.csv\", \n",
    "                \"Location\", \n",
    "                \"locationId\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/service_requests.csv\", \n",
    "                \"ServiceRequest\", \n",
    "                \"requestId\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error creating Nodes in Neo4j: {e}\")\n",
    "\n",
    "\n",
    "    def load_relationships(self):\n",
    "        \n",
    "        REL_DIR = Path(\"./neo4j_relationships\")\n",
    "\n",
    "        try:\n",
    "            # Load relationships\n",
    "            \n",
    "            # Asset -> Location\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/LOCATED_AT.csv\",\n",
    "                {\n",
    "                    'rel_type': 'LOCATED_AT',\n",
    "                    'from_label': 'Asset',\n",
    "                    'from_id_col': 'assetId',\n",
    "                    'from_id_prop': 'assetId',\n",
    "                    'to_label': 'Location',\n",
    "                    'to_id_col': 'locationId',\n",
    "                    'to_id_prop': 'locationId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # ServiceRequest -> Location\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/AT_LOCATION.csv\",\n",
    "                {\n",
    "                    'rel_type': 'AT_LOCATION',\n",
    "                    'from_label': 'ServiceRequest',\n",
    "                    'from_id_col': 'requestId',\n",
    "                    'from_id_prop': 'requestId',\n",
    "                    'to_label': 'Location',\n",
    "                    'to_id_col': 'locationId',\n",
    "                    'to_id_prop': 'locationId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # ServiceRequest -> Activity\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/HAS_ACTIVITY.csv\",\n",
    "                {\n",
    "                    'rel_type': 'HAS_ACTIVITY',\n",
    "                    'from_label': 'ServiceRequest',\n",
    "                    'from_id_col': 'requestId',\n",
    "                    'from_id_prop': 'requestId',\n",
    "                    'to_label': 'Activity',\n",
    "                    'to_id_col': 'activityId',\n",
    "                    'to_id_prop': 'activityId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # ServiceRequest -> Asset\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/FOR_ASSET.csv\",\n",
    "                {\n",
    "                    'rel_type': 'FOR_ASSET',\n",
    "                    'from_label': 'ServiceRequest',\n",
    "                    'from_id_col': 'requestId',\n",
    "                    'from_id_prop': 'requestId',\n",
    "                    'to_label': 'Asset',\n",
    "                    'to_id_col': 'assetId',\n",
    "                    'to_id_prop': 'assetId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> Country\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/OPERATES_IN.csv\",\n",
    "                {\n",
    "                    'rel_type': 'OPERATES_IN',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'Country',\n",
    "                    'to_id_col': 'country',\n",
    "                    'to_id_prop': 'country'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> Location\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/RESIDES_AT.csv\",\n",
    "                {\n",
    "                    'rel_type': 'RESIDES_AT',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'Location',\n",
    "                    'to_id_col': 'locationId',\n",
    "                    'to_id_prop': 'locationId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> Asset\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/OWNS.csv\",\n",
    "                {\n",
    "                    'rel_type': 'OWNS',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'Asset',\n",
    "                    'to_id_col': 'assetId',\n",
    "                    'to_id_prop': 'assetId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> ServiceRequest\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/CREATES.csv\",\n",
    "                {\n",
    "                    'rel_type': 'CREATES',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'ServiceRequest',\n",
    "                    'to_id_col': 'requestId',\n",
    "                    'to_id_prop': 'requestId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Location -> Country\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/IN.csv\",\n",
    "                {\n",
    "                    'rel_type': 'IN',\n",
    "                    'from_label': 'Location',\n",
    "                    'from_id_col': 'locationId',\n",
    "                    'from_id_prop': 'locationId',\n",
    "                    'to_label': 'Country',\n",
    "                    'to_id_col': 'country',\n",
    "                    'to_id_prop': 'country'\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error creating Relationships for nodes on Neo4j: {e}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f89e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Downloaded 455236 rows from 'v_requests', 508830 rows from 'v_assets', and 469852 rows from 'v_request_with_activities'.\n",
      "Data exported to ./fetched_data\n",
      "Helper CSV files loaded successfully.\n",
      "Data for migration to Neo4J is saved on path: ./neo4j_data and ready to be imported!\n",
      "Relationships created and saved to path: ./neo4j_relationships\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    dataLoader = DataLoader('config.ini')\n",
    "    dataLoader.executor()\n",
    "\n",
    "except NameError:\n",
    "    logger.warning(\"The DataLoader class is not defined. Please ensure it is defined correctly.\")\n",
    "\n",
    "try:\n",
    "    dataMigrator = DataMigrator('config.ini')\n",
    "    dataMigrator.executor()\n",
    "\n",
    "except NameError:\n",
    "    logger.warning(\"The DataMigrator class is not defined. Please ensure it is defined correctly.\")\n",
    "\n",
    "\n",
    "#to-do:\n",
    "# --> define paths for csvs in config.ini -- cosmetic, later\n",
    "# --> filter features from 'final_data' -- done\n",
    "# --> create csvs/dfs for neo4j migration -- done\n",
    "# --> migration!! -- on going\n",
    "\n",
    "# Data_migrator('config.ini', target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_df, assets_df, country_df, customer_df, location_df, service_req_df = dfs\n",
    "# print(final_data.columns)\n",
    "\n",
    "# # save CSVs for neo4j import:\n",
    "# neo4j_dir_path = './neo4j_data'\n",
    "# Path(neo4j_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# try:\n",
    "#     activity_df.to_csv(f\"{neo4j_dir_path}/activities.csv\",index=False)\n",
    "#     assets_df.to_csv(f\"{neo4j_dir_path}/assets.csv\",index=False)\n",
    "#     country_df.to_csv(f\"{neo4j_dir_path}/countries.csv\",index=False)\n",
    "#     customer_df.to_csv(f\"{neo4j_dir_path}/customers.csv\",index=False)\n",
    "#     location_df.to_csv(f\"{neo4j_dir_path}/location.csv\",index=False)\n",
    "#     service_req_df.to_csv(f\"{neo4j_dir_path}/service_requests.csv\",index=False)\n",
    "\n",
    "# except NameError:\n",
    "#     print(\"CSVs not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304260d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_injestion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
