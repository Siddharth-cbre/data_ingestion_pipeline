{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a03f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "import configparser\n",
    "# import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbb622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9229f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, config_file_path):\n",
    "\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.warning(f\"Config file {config_file_path} not found!\")\n",
    "        \n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_file_path)\n",
    "\n",
    "        if 'DATABASE' not in config:\n",
    "            raise ValueError(\"DATABASE section not found in config\")\n",
    "        \n",
    "        db_config = {\n",
    "            'host': config['DATABASE']['host'],\n",
    "            'port': int(config['DATABASE']['port']),\n",
    "            'username': config['DATABASE']['username'],\n",
    "            'password': config['DATABASE']['password'],\n",
    "            'database': config['DATABASE']['database'],\n",
    "            'query_request': config['DATABASE']['query1'],\n",
    "            'query_assets': config['DATABASE']['query2'],\n",
    "            'query_request_with_activities': config['DATABASE']['query3'],\n",
    "            'schema': config['DATABASE']['schema']\n",
    "        }\n",
    "\n",
    "        self.db_host = db_config.get('host')\n",
    "        self.db_port = db_config.get('port')\n",
    "        self.db_username = db_config.get('username')\n",
    "        self.db_password = db_config.get('password')\n",
    "        self.db_database = db_config.get('database')\n",
    "        self.db_query1 = db_config.get('query_request')\n",
    "        self.db_query2 = db_config.get('query_assets')\n",
    "        self.db_query3 = db_config.get('query_request_with_activities')\n",
    "        self.db_schema = db_config.get('schema')   \n",
    "            \n",
    "    def executor(self):\n",
    "        self.conn_string = self.database_connector(\n",
    "            db_type='postgresql',\n",
    "            host=self.db_host,\n",
    "            port=self.db_port,\n",
    "            database=self.db_database,\n",
    "            username=self.db_username,\n",
    "            password=self.db_password,\n",
    "            schema=self.db_schema\n",
    "            )\n",
    "        \n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"LOADING DATA\")\n",
    "        logger.info(\"=\" * 50)\n",
    "\n",
    "        self.load_and_save_data()\n",
    "        self.load_CSVs()\n",
    "        self.data_preprocessor()\n",
    "        self.save_neo4j_CSVs()\n",
    "        self.create_and_save_relationships()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"DATA LOADING SUCCESSFUL!\")\n",
    "        logger.info(\"=\" * 50)\n",
    "\n",
    "\n",
    "    def database_connector(self, db_type, host, port, database, username, password, **kwargs):\n",
    "    \n",
    "        encoded_password = urllib.parse.quote_plus(password)\n",
    "        connection_strings = {\n",
    "            'postgresql': f\"postgresql://{username}:{encoded_password}@{host}:{port}/{database}\",\n",
    "        }\n",
    "        return connection_strings[db_type]\n",
    "\n",
    "\n",
    "    def load_and_save_data(self):\n",
    "        \n",
    "        target_dir_path = './fetched_data'\n",
    "        Path(target_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            engine = create_engine(self.conn_string)\n",
    "            \n",
    "            if not self.db_query1:\n",
    "                logger.warning(\"Query for v_request is missing!\")\n",
    "                return None \n",
    "        \n",
    "            if not self.db_query2:\n",
    "                logger.warning(\"Query for v_assets is missing!\")\n",
    "                return None\n",
    "            \n",
    "            if not self.db_query3:\n",
    "                logger.warning(\"Query for v_request_with_activities is missing!\")\n",
    "                return None\n",
    "\n",
    "            self.df_request = pd.read_sql(self.db_query1, engine)\n",
    "            self.df_assets = pd.read_sql(self.db_query2, engine)\n",
    "            self.df_request_with_activities = pd.read_sql(self.db_query3, engine)\n",
    "            \n",
    "            logger.info(f\" Downloaded {len(self.df_request)} rows from 'v_requests', {len(self.df_assets)} rows from 'v_assets', and {len(self.df_request_with_activities)} rows from 'v_request_with_activities'.\")\n",
    "            \n",
    "            self.df_request.to_csv(f\"{target_dir_path}/v_requests.csv\",index=False)\n",
    "            self.df_assets.to_csv(f\"{target_dir_path}/v_assets.csv\",index=False)\n",
    "            self.df_request_with_activities.to_csv(f\"{target_dir_path}/v_requests_with_activities.csv\",index=False)\n",
    "            \n",
    "            logger.info(f\"Data exported to {target_dir_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error connecting to database: {e}\")\n",
    "            return None\n",
    "        \n",
    "        finally:\n",
    "            if 'engine' in locals():\n",
    "                engine.dispose()\n",
    "\n",
    "    def create_and_save_relationships(self):\n",
    "\n",
    "        neo4j_relationship_dir_path = './neo4j_relationships'\n",
    "        Path(neo4j_relationship_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            # self.LOCATED_AT = self.df_request[['assetAlternateId','locationAlternateId']].dropna().drop_duplicates()\n",
    "            # self.LOCATED_AT.rename(columns={'assetAlternateId': 'assetId', 'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.LOCATED_AT = self.df_assets[['Asset Alt Id', 'Location Alt Id']].dropna().drop_duplicates()\n",
    "            self.LOCATED_AT.rename(columns={'Asset Alt Id': 'assetId', 'Location Alt Id': 'locationId'}, inplace=True)\n",
    "            self.LOCATED_AT.to_csv(f\"{neo4j_relationship_dir_path}/LOCATED_AT.csv\",index=False)\n",
    "\n",
    "            self.AT_LOCATION = self.df_request[['requestAlternateId','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.AT_LOCATION.rename(columns={'requestAlternateId': 'requestId', 'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.AT_LOCATION.to_csv(f\"{neo4j_relationship_dir_path}/AT_LOCATION.csv\",index=False)\n",
    "\n",
    "            self.HAS_ACTIVITY = self.df_request_with_activities[['activityAlternateId', 'requestAlternateId']].dropna().drop_duplicates()\n",
    "            self.HAS_ACTIVITY.rename(columns={'requestAlternateId': 'requestId', 'activityAlternateId': 'activityId'}, inplace=True)\n",
    "            self.HAS_ACTIVITY.to_csv(f\"{neo4j_relationship_dir_path}/HAS_ACTIVITY.csv\",index=False)\n",
    "\n",
    "            # self.FOR_ASSET = self.df_request[['requestAlternateId','assetAlternateId']].dropna().drop_duplicates()\n",
    "            # self.FOR_ASSET.rename(columns={'requestAlternateId': 'requestId', 'assetAlternateId': 'assetId'}, inplace=True)\n",
    "            self.FOR_ASSET = self.df_assets.merge(self.df_request, left_on='Asset Alt Id', right_on='assetAlternateId', how='left')[['requestAlternateId','Asset Alt Id']].dropna().drop_duplicates()\n",
    "            self.FOR_ASSET.rename(columns={'requestAlternateId': 'requestId', 'Asset Alt Id': 'assetId'}, inplace=True)\n",
    "            self.FOR_ASSET.to_csv(f\"{neo4j_relationship_dir_path}/FOR_ASSET.csv\",index=False)\n",
    "\n",
    "            self.OPERATES_IN = self.df_request[['customer','country']].dropna().drop_duplicates()\n",
    "            self.OPERATES_IN.to_csv(f\"{neo4j_relationship_dir_path}/OPERATES_IN.csv\",index=False)\n",
    "\n",
    "            self.RESIDES_AT = self.df_request[['customer','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.RESIDES_AT.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.RESIDES_AT.to_csv(f\"{neo4j_relationship_dir_path}/RESIDES_AT.csv\",index=False)\n",
    "\n",
    "            # self.OWNS = self.df_request[['customer','assetAlternateId']].dropna().drop_duplicates()\n",
    "            # self.OWNS.rename(columns={'assetAlternateId': 'assetId'}, inplace=True)\n",
    "            self.OWNS = self.df_assets[['Customer','Asset Alt Id']].dropna().drop_duplicates()\n",
    "            self.OWNS.rename(columns={'Customer': 'customer', 'Asset Alt Id': 'assetId'}, inplace=True)\n",
    "            self.OWNS.to_csv(f\"{neo4j_relationship_dir_path}/OWNS.csv\",index=False)\n",
    "\n",
    "            self.CREATES = self.df_request[['customer','requestAlternateId']].dropna().drop_duplicates()\n",
    "            self.CREATES.rename(columns={'requestAlternateId': 'requestId'}, inplace=True)\n",
    "            self.CREATES.to_csv(f\"{neo4j_relationship_dir_path}/CREATES.csv\",index=False)\n",
    "\n",
    "            self.IN = self.df_request[['country','locationAlternateId']].dropna().drop_duplicates()\n",
    "            self.IN.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "            self.IN.to_csv(f\"{neo4j_relationship_dir_path}/IN.csv\",index=False)\n",
    "\n",
    "            logger.info(f\"Relationships created and saved to path: {neo4j_relationship_dir_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            logger.warning(f\"Error while creating and saving relationships: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    def load_CSVs(self):\n",
    "        self.is_hvac_df = pd.read_csv('./data/hvac_assets/IFM_Assets_RuleBasedEngineResults(IFM_Assets_RuleBasedEngineResul).csv')\n",
    "        self.suggested_asset_df = pd.read_csv('./data/asset_suggest_data/asset_suggest_model.csv')\n",
    "        self.vendor_data = pd.read_csv('./data/asset_vendor/request_act_vendor.csv')\n",
    "\n",
    "        logger.info(\"Helper CSV files loaded successfully.\")\n",
    "        \n",
    "    \n",
    "    def data_preprocessor(self):\n",
    "\n",
    "        # Activity:\n",
    "        activity_df = self.df_request_with_activities[self.df_request_with_activities['activityAlternateId'].notna()][['providertype','activityAlternateId','activityDescription']]\n",
    "        activity_df.drop_duplicates(inplace = True)\n",
    "\n",
    "        # Asset:\n",
    "        requests_subset = self.df_request[['requestId','assetAlternateId', 'requestAlternateId']]\n",
    "        requests_subset = requests_subset[requests_subset.assetAlternateId.notna()]\n",
    "\n",
    "        v_assets = self.df_assets[['assetId','Asset Alt Id', 'Asset Description', 'manufacturer', 'model', 'serialNumber']]\n",
    "        v_assets = v_assets.merge(requests_subset, left_on = 'Asset Alt Id', right_on = 'assetAlternateId', how= 'left')\n",
    "        # v_assets = v_assets[v_assets['requestAlternateId'].notna()] # keeping only those asset records which are associated to the presently fetched serviceRequests\n",
    "\n",
    "        is_hvac_df = self.is_hvac_df.copy()\n",
    "        is_hvac_df['is_HVAC'] = True\n",
    "        is_hvac_df.drop(columns=['Asset Description'], inplace = True)\n",
    "        v_assets_with_hvac = v_assets.merge(is_hvac_df, on='Asset Alt Id', how='left')\n",
    "        # v_assets_with_hvac.loc[v_assets_with_hvac['is_HVAC'] == True, 'asset_type'] = 'HVAC'\n",
    "        \n",
    "        if not v_assets_with_hvac.empty:\n",
    "            v_assets_with_hvac.loc[v_assets_with_hvac['is_HVAC'] == True, 'asset_type'] = 'HVAC'\n",
    "        else:\n",
    "            v_assets_with_hvac['asset_type'] = None\n",
    "\n",
    "        final_assets_df = v_assets_with_hvac[['assetId', 'Asset Description', 'Asset Alt Id', 'manufacturer', 'model',\n",
    "                                              'serialNumber', 'is_HVAC', 'asset_type', 'requestId','assetAlternateId', 'requestAlternateId']]\n",
    "        final_assets_df.loc[:, 'is_HVAC'] = final_assets_df['is_HVAC'].fillna(False)\n",
    "\n",
    "        suggested_asset_df = self.suggested_asset_df.copy()\n",
    "        suggested_asset_df.rename(columns={'asset_id': 'suggested_asset'}, inplace=True)\n",
    "        suggested_asset_df_subset = suggested_asset_df[['request_id', 'suggested_asset']]\n",
    "\n",
    "        final_assets_df = final_assets_df.merge(suggested_asset_df_subset, left_on = 'requestId', right_on = 'request_id', how = 'left')\n",
    "        final_assets_df = final_assets_df[['assetId', 'Asset Description', 'Asset Alt Id', 'manufacturer', 'model',\n",
    "                                           'serialNumber', 'is_HVAC', 'asset_type', 'suggested_asset','requestAlternateId']]\n",
    "        \n",
    "        vendor_data = self.vendor_data.copy()\n",
    "        vendor_data = vendor_data[['requestAlternateId','vendorName', 'vendorAddress1', 'vendorCity',\n",
    "                           'vendorRegion', 'vendorCountry', 'vendorPostalCode']]\n",
    "        assets_with_vendors = final_assets_df.merge(vendor_data, on = 'requestAlternateId', how = 'left')\n",
    "        assets_df = assets_with_vendors[['Asset Description', 'Asset Alt Id', 'manufacturer', 'model','serialNumber', \n",
    "                                                   'is_HVAC', 'asset_type', 'suggested_asset','vendorName', 'vendorAddress1', 'vendorCity',\n",
    "                                                   'vendorRegion', 'vendorCountry', 'vendorPostalCode']]\n",
    "\n",
    "        # Country:\n",
    "        country_df = self.df_request[['country']].drop_duplicates()\n",
    "\n",
    "        # Customer:\n",
    "        customer_df = self.df_request[['customer']].drop_duplicates()\n",
    "\n",
    "        # Location:\n",
    "        location_df = self.df_request[['locationAlternateId', 'locationPath']].drop_duplicates()\n",
    "\n",
    "        # Service Requests:\n",
    "        temp_ser_req = self.df_request[['isSelfAssign', 'priorityCode', \n",
    "                  'requestCreatedDate', 'requestDescription', 'requestAlternateId', 'completionNotes', \n",
    "                  'requestTargetCompletionDate', 'serviceClassificationAlternateId', 'serviceClassificationPath',  \n",
    "                  'requestCompletionDate', 'workType', 'requestModifiedDate']]\n",
    "        \n",
    "        def to_local_datetime(date_col):\n",
    "    \n",
    "            if date_col is None:\n",
    "                return None\n",
    "            \n",
    "            if date_col.isna().all():\n",
    "                return date_col\n",
    "            \n",
    "            dt_series = pd.to_datetime(date_col, format='mixed')\n",
    "            formatted = dt_series.dt.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]\n",
    "            formatted_transformed = formatted.str.replace(' ', 'T')\n",
    "\n",
    "            return formatted_transformed\n",
    "\n",
    "\n",
    "        def process_service_requests(df_service_request):\n",
    "                \n",
    "                date_cols = ['requestCreatedDate', 'requestTargetCompletionDate', 'requestCompletionDate', 'requestModifiedDate']\n",
    "                \n",
    "                for col in date_cols:\n",
    "                    if col in df_service_request.columns:\n",
    "                        # df_service_request.loc[:, col] = to_local_datetime(df_service_request[col]).astype(str) # not working- pandas replaces 'T' with a ' ' again\n",
    "                        df_service_request[col] = to_local_datetime(df_service_request[col])\n",
    "                \n",
    "                df_service_request['createdYear'] = pd.to_datetime(df_service_request['requestCreatedDate']).dt.year\n",
    "                df_service_request['createdMonth'] = pd.to_datetime(df_service_request['requestCreatedDate']).dt.month\n",
    "                \n",
    "                \n",
    "                df_service_request['isCompleted'] = df_service_request['requestCompletionDate'].notna()\n",
    "                \n",
    "                \n",
    "                conditions = [\n",
    "                    df_service_request['requestCompletionDate'].isna(),\n",
    "                    df_service_request['requestTargetCompletionDate'].isna(),\n",
    "                    df_service_request['requestCompletionDate'] <= df_service_request['requestTargetCompletionDate'],\n",
    "                    df_service_request['requestCompletionDate'] > df_service_request['requestTargetCompletionDate']\n",
    "                ]\n",
    "                \n",
    "                choices = ['Open', 'Open', 'Met', 'Miss']\n",
    "                \n",
    "                df_service_request['sla'] = np.select(conditions, choices, default='Unknown')\n",
    "                \n",
    "                return df_service_request\n",
    "\n",
    "        \n",
    "        service_req_df = process_service_requests(temp_ser_req)\n",
    "\n",
    "        self.activity_df = activity_df.copy()\n",
    "        self.assets_df = assets_df.copy()\n",
    "        self.country_df = country_df.copy()\n",
    "        self.customer_df = customer_df.copy()\n",
    "        self.location_df = location_df.copy()\n",
    "        self.service_req_df = service_req_df.copy()\n",
    "        logger.info(\"Node and Property data prepared!\")\n",
    "\n",
    "    def save_neo4j_CSVs(self):\n",
    "        neo4j_dir_path = './neo4j_data'\n",
    "        Path(neo4j_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # renaming the features:\n",
    "            self.activity_df.rename(columns={'activityAlternateId': 'activityId', 'providertype':'providerType'}, inplace=True)\n",
    "\n",
    "            self.assets_df.rename(columns={'Asset Alt Id': 'assetId', 'Asset Description':'assetDescription', 'vendorAddress1':'vendorAddress'}, inplace=True)\n",
    "\n",
    "            self.location_df.rename(columns={'locationAlternateId': 'locationId'}, inplace=True)\n",
    "\n",
    "            self.service_req_df.rename(columns={'requestAlternateId': 'requestId', 'serviceClassificationAlternateId': 'serviceClassificationId'}, inplace=True)\n",
    "\n",
    "            # Verifying if duplicates are present before saving: \n",
    "            self.activity_df.drop_duplicates(inplace=True)\n",
    "            self.assets_df.drop_duplicates(inplace=True)\n",
    "            self.country_df.drop_duplicates(inplace=True)\n",
    "            self.customer_df.drop_duplicates(inplace=True)\n",
    "            self.location_df.drop_duplicates(inplace=True)\n",
    "            self.service_req_df.drop_duplicates(inplace=True)\n",
    "            \n",
    "            # saving the data\n",
    "            self.activity_df.to_csv(f\"{neo4j_dir_path}/activities.csv\",index=False)\n",
    "            self.assets_df.to_csv(f\"{neo4j_dir_path}/assets.csv\",index=False)\n",
    "            self.country_df.to_csv(f\"{neo4j_dir_path}/countries.csv\",index=False)\n",
    "            self.customer_df.to_csv(f\"{neo4j_dir_path}/customers.csv\",index=False)\n",
    "            self.location_df.to_csv(f\"{neo4j_dir_path}/location.csv\",index=False)\n",
    "            self.service_req_df.to_csv(f\"{neo4j_dir_path}/service_requests.csv\",index=False)\n",
    "\n",
    "            logger.info(f\"Data for migration to Neo4J is saved on path: {neo4j_dir_path} and ready to be imported!\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error saving CSVs: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataMigrator:\n",
    "\n",
    "    def __init__(self, config_file_path):\n",
    "\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.warning(f\"Config file {config_file_path} not found!\")\n",
    "        \n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_file_path)\n",
    "\n",
    "        if 'Neo4j' not in config:\n",
    "            raise ValueError(\"Neo4j section not found in config\")\n",
    "        \n",
    "        nj_config = {\n",
    "            'url': config['Neo4j']['url'],\n",
    "            'username': config['Neo4j']['username'],\n",
    "            'password': config['Neo4j']['password']\n",
    "        }\n",
    "\n",
    "        self.nj_url = nj_config.get('url')\n",
    "        self.nj_username = nj_config.get('username')\n",
    "        self.nj_password = nj_config.get('password')\n",
    "\n",
    "        self.driver = GraphDatabase.driver(self.nj_url, auth=(self.nj_username, self.nj_password))\n",
    "        \n",
    "        # self.executor()\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def clear_database(self):\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "\n",
    "            # Delete all nodes and relationships:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            logger.info(\"All nodes and relationships deleted\")\n",
    "            \n",
    "            # Delete all indexes:\n",
    "            result = session.run(\"SHOW INDEXES\")\n",
    "            for record in result:\n",
    "                index_name = record.get(\"name\") or record.get(\"indexName\")\n",
    "                if index_name:\n",
    "                    try:\n",
    "                        session.run(f\"DROP INDEX {index_name}\")\n",
    "                        logger.info(f\"Dropped index: {index_name}\")\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Could not drop index {index_name}: {e}\")\n",
    "            \n",
    "            # Delete all constraints:\n",
    "            result = session.run(\"SHOW CONSTRAINTS\")\n",
    "            for record in result:\n",
    "                constraint_name = record.get(\"name\")\n",
    "                if constraint_name:\n",
    "                    try:\n",
    "                        session.run(f\"DROP CONSTRAINT {constraint_name}\")\n",
    "                        logger.info(f\"Dropped constraint: {constraint_name}\")\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Could not drop constraint {constraint_name}: {e}\")\n",
    "            \n",
    "            logger.info(\"Database completely cleared\")\n",
    "\n",
    "    def create_constraints(self):\n",
    "        constraints = [\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (a:Activity) REQUIRE a.activityId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (as:Asset) REQUIRE as.assetId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (l:Location) REQUIRE l.locationId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (s:ServiceRequest) REQUIRE s.requestId IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (c:Country) REQUIRE c.country IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (cu:Customer) REQUIRE cu.customer IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT  IF NOT EXISTS FOR (s:ServiceRequest) REQUIRE s.serviceClassificationId IS UNIQUE\"\n",
    "        ]\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for constraint in constraints:\n",
    "                try:\n",
    "                    session.run(constraint)\n",
    "                    logger.info(f\"Created constraint: {constraint.split('FOR')[1].split('REQUIRE')[0].strip()}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Constraint may already exist: {e}\")\n",
    "\n",
    "\n",
    "    def create_indexes(self):\n",
    "        \n",
    "        indexes = [\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (a:Asset) ON (a.assetId)\",\n",
    "\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdYear)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.isCompleted)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdMonth)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.sla)\",\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.requestId)\",\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.serviceClassificationId)\" ,\n",
    "\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (c:Customer) ON (c.customer)\",\n",
    "            \n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (l:Location) ON (l.locationId),\"\n",
    "\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (ac:Activity) ON (ac.activityId),\"\n",
    "\n",
    "            # \"CREATE INDEX IF NOT EXISTS FOR (cn:Country) ON (cn.country)\"\n",
    "\n",
    "        ]\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for index in indexes:\n",
    "                try:\n",
    "                    session.run(index)\n",
    "                    logger.info(f\"Created index: {index}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Index may already exist: {e}\")\n",
    "\n",
    "\n",
    "    def load_nodes_from_csv(self, csv_path: str, node_label: str, id_property: str, batch_size: int = 20000):\n",
    "        \"\"\"Load nodes from CSV file in batches.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df.where(pd.notnull(df), None)  # Replace NaN with None\n",
    "        \n",
    "        total_rows = len(df)\n",
    "        logger.info(f\"Loading {total_rows} {node_label} nodes from {csv_path}\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for i in range(0, total_rows, batch_size):\n",
    "                batch = df.iloc[i:i+batch_size]\n",
    "                records = batch.to_dict('records')\n",
    "                \n",
    "                # Build Cypher query dynamically\n",
    "                # changing from 'SET n += record' to perform overwrite instead of merge\n",
    "                query = f\"\"\"\n",
    "                UNWIND $records AS record\n",
    "                MERGE (n:{node_label} {{{id_property}: record.{id_property}}})\n",
    "                SET n = record\n",
    "                \"\"\"\n",
    "                \n",
    "                session.run(query, records=records)\n",
    "                logger.info(f\"Loaded batch {i//batch_size + 1}/{(total_rows-1)//batch_size + 1} for {node_label}\")\n",
    "        \n",
    "        logger.info(f\"Completed loading {node_label} nodes\")\n",
    "\n",
    "\n",
    "    def load_relationships_from_csv(self, csv_path: str, rel_config: Dict, batch_size: int = 20000):\n",
    "        \"\"\"\n",
    "        Load relationships from CSV file.\n",
    "        \n",
    "        rel_config example:\n",
    "        {\n",
    "            'rel_type': 'LOCATED_AT',\n",
    "            'from_label': 'Asset',\n",
    "            'from_id_col': 'assetId',\n",
    "            'from_id_prop': 'assetId',\n",
    "            'to_label': 'Location',\n",
    "            'to_id_col': 'locationId',\n",
    "            'to_id_prop': 'locationId',\n",
    "            'properties': []  # Optional: list of relationship properties\n",
    "        }\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "        \n",
    "        total_rows = len(df)\n",
    "        logger.info(f\"Loading {total_rows} {rel_config['rel_type']} relationships from {csv_path}\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for i in range(0, total_rows, batch_size):\n",
    "                batch = df.iloc[i:i+batch_size]\n",
    "                records = batch.to_dict('records')\n",
    "                \n",
    "                # Build relationship properties string if any\n",
    "                rel_props = \"\"\n",
    "                if rel_config.get('properties'):\n",
    "                    props_str = \", \".join([f\"{p}: record.{p}\" for p in rel_config['properties']])\n",
    "                    rel_props = f\" {{{props_str}}}\"\n",
    "                \n",
    "                query = f\"\"\"\n",
    "                UNWIND $records AS record\n",
    "                MATCH (from:{rel_config['from_label']} {{{rel_config['from_id_prop']}: record.{rel_config['from_id_col']}}})\n",
    "                MATCH (to:{rel_config['to_label']} {{{rel_config['to_id_prop']}: record.{rel_config['to_id_col']}}})\n",
    "                MERGE (from)-[r:{rel_config['rel_type']}]->(to)\n",
    "                \"\"\"\n",
    "                \n",
    "                if rel_props:\n",
    "                    query += f\"\\nSET r = {{{', '.join([f'{p}: record.{p}' for p in rel_config['properties']])}}}\"     # changing from 'SET r += ' for overwrite instead of merge\n",
    "                \n",
    "                session.run(query, records=records)\n",
    "                logger.info(f\"Loaded batch {i//batch_size + 1}/{(total_rows-1)//batch_size + 1} for {rel_config['rel_type']}\")\n",
    "        \n",
    "        logger.info(f\"Completed loading {rel_config['rel_type']} relationships\")\n",
    "    \n",
    "\n",
    "    def verify_load(self):\n",
    "        \"\"\"Verify the data load by counting nodes and relationships.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Count nodes\n",
    "            node_labels = ['Activity', 'Asset', 'Country', 'Customer', 'Location', 'ServiceRequest']\n",
    "            for label in node_labels:\n",
    "                result = session.run(f\"MATCH (n:{label}) RETURN count(n) as count\")\n",
    "                count = result.single()['count']\n",
    "                logger.info(f\"{label} nodes: {count}\")\n",
    "            \n",
    "            # Count relationships\n",
    "            result = session.run(\"MATCH ()-[r]->() RETURN type(r) as type, count(r) as count\")\n",
    "            for record in result:\n",
    "                logger.info(f\"{record['type']} relationships: {record['count']}\")\n",
    "\n",
    "    \n",
    "    def executor(self):\n",
    "\n",
    "        # # CAUTION: Deleting the existing graph!!!\n",
    "        # logger.info(\"=\" * 50)\n",
    "        # logger.info(\"DELETING THE EXISTING GRAPH!!\")\n",
    "        # logger.info(\"=\" * 50) \n",
    "        # self.clear_database()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"LOADING NODES\")\n",
    "        logger.info(\"=\" * 50)        \n",
    "        self.load_nodes()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"LOADING RELATIONSHIPS\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        self.load_relationships()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"VERIFYING NODE AND RELATIONSHP CREATION.\")\n",
    "        logger.info(\"=\" * 50)\n",
    "        self.verify_load()\n",
    "\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"DATA MIGRATION SUCCESSFUL!\")\n",
    "        logger.info(\"=\" * 50)\n",
    "\n",
    "        self.close()\n",
    "\n",
    "    \n",
    "    def load_nodes(self):\n",
    "        \n",
    "        DATA_DIR = Path(\"./neo4j_data\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Create constraints and indexes\n",
    "            self.create_constraints()\n",
    "            self.create_indexes()\n",
    "            \n",
    "            # Load nodes\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/activities.csv\", \n",
    "                \"Activity\", \n",
    "                \"activityId\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/assets.csv\", \n",
    "                \"Asset\", \n",
    "                \"assetId\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/countries.csv\", \n",
    "                \"Country\", \n",
    "                \"country\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/customers.csv\", \n",
    "                \"Customer\", \n",
    "                \"customer\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/location.csv\", \n",
    "                \"Location\", \n",
    "                \"locationId\"\n",
    "            )\n",
    "            \n",
    "            self.load_nodes_from_csv(\n",
    "                f\"{DATA_DIR}/service_requests.csv\", \n",
    "                \"ServiceRequest\", \n",
    "                \"requestId\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error creating Nodes in Neo4j: {e}\")\n",
    "\n",
    "\n",
    "    def load_relationships(self):\n",
    "        \n",
    "        REL_DIR = Path(\"./neo4j_relationships\")\n",
    "\n",
    "        try:\n",
    "            # Load relationships\n",
    "            \n",
    "            # Asset -> Location\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/LOCATED_AT.csv\",\n",
    "                {\n",
    "                    'rel_type': 'LOCATED_AT',\n",
    "                    'from_label': 'Asset',\n",
    "                    'from_id_col': 'assetId',\n",
    "                    'from_id_prop': 'assetId',\n",
    "                    'to_label': 'Location',\n",
    "                    'to_id_col': 'locationId',\n",
    "                    'to_id_prop': 'locationId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # ServiceRequest -> Location\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/AT_LOCATION.csv\",\n",
    "                {\n",
    "                    'rel_type': 'AT_LOCATION',\n",
    "                    'from_label': 'ServiceRequest',\n",
    "                    'from_id_col': 'requestId',\n",
    "                    'from_id_prop': 'requestId',\n",
    "                    'to_label': 'Location',\n",
    "                    'to_id_col': 'locationId',\n",
    "                    'to_id_prop': 'locationId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # ServiceRequest -> Activity\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/HAS_ACTIVITY.csv\",\n",
    "                {\n",
    "                    'rel_type': 'HAS_ACTIVITY',\n",
    "                    'from_label': 'ServiceRequest',\n",
    "                    'from_id_col': 'requestId',\n",
    "                    'from_id_prop': 'requestId',\n",
    "                    'to_label': 'Activity',\n",
    "                    'to_id_col': 'activityId',\n",
    "                    'to_id_prop': 'activityId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # ServiceRequest -> Asset\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/FOR_ASSET.csv\",\n",
    "                {\n",
    "                    'rel_type': 'FOR_ASSET',\n",
    "                    'from_label': 'ServiceRequest',\n",
    "                    'from_id_col': 'requestId',\n",
    "                    'from_id_prop': 'requestId',\n",
    "                    'to_label': 'Asset',\n",
    "                    'to_id_col': 'assetId',\n",
    "                    'to_id_prop': 'assetId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> Country\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/OPERATES_IN.csv\",\n",
    "                {\n",
    "                    'rel_type': 'OPERATES_IN',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'Country',\n",
    "                    'to_id_col': 'country',\n",
    "                    'to_id_prop': 'country'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> Location\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/RESIDES_AT.csv\",\n",
    "                {\n",
    "                    'rel_type': 'RESIDES_AT',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'Location',\n",
    "                    'to_id_col': 'locationId',\n",
    "                    'to_id_prop': 'locationId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> Asset\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/OWNS.csv\",\n",
    "                {\n",
    "                    'rel_type': 'OWNS',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'Asset',\n",
    "                    'to_id_col': 'assetId',\n",
    "                    'to_id_prop': 'assetId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Customer -> ServiceRequest\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/CREATES.csv\",\n",
    "                {\n",
    "                    'rel_type': 'CREATES',\n",
    "                    'from_label': 'Customer',\n",
    "                    'from_id_col': 'customer',\n",
    "                    'from_id_prop': 'customer',\n",
    "                    'to_label': 'ServiceRequest',\n",
    "                    'to_id_col': 'requestId',\n",
    "                    'to_id_prop': 'requestId'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Location -> Country\n",
    "            self.load_relationships_from_csv(\n",
    "                f\"{REL_DIR}/IN.csv\",\n",
    "                {\n",
    "                    'rel_type': 'IN',\n",
    "                    'from_label': 'Location',\n",
    "                    'from_id_col': 'locationId',\n",
    "                    'from_id_prop': 'locationId',\n",
    "                    'to_label': 'Country',\n",
    "                    'to_id_col': 'country',\n",
    "                    'to_id_prop': 'country'\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error creating Relationships for nodes on Neo4j: {e}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "425f89e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:==================================================\n",
      "INFO:__main__:LOADING DATA\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__: Downloaded 597107 rows from 'v_requests', 568930 rows from 'v_assets', and 613328 rows from 'v_request_with_activities'.\n",
      "INFO:__main__:Data exported to ./fetched_data\n",
      "INFO:__main__:Helper CSV files loaded successfully.\n",
      "INFO:__main__:Node and Property data prepared!\n",
      "INFO:__main__:Data for migration to Neo4J is saved on path: ./neo4j_data and ready to be imported!\n",
      "INFO:__main__:Relationships created and saved to path: ./neo4j_relationships\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:DATA LOADING SUCCESSFUL!\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:LOADING NODES\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:Created constraint: (a:Activity)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:Activity) REQUIRE (e.activityId) IS UNIQUE' has no effect. The index or constraint specified by 'CONSTRAINT activityId_Activity_uniq FOR (e:Activity) REQUIRE (e.activityId) IS UNIQUE' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE CONSTRAINT  IF NOT EXISTS FOR (a:Activity) REQUIRE a.activityId IS UNIQUE'\n",
      "INFO:__main__:Created constraint: (as:Asset)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:Asset) REQUIRE (e.assetId) IS UNIQUE' has no effect. The index or constraint specified by 'CONSTRAINT assetId_Asset_uniq FOR (e:Asset) REQUIRE (e.assetId) IS UNIQUE' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE CONSTRAINT  IF NOT EXISTS FOR (as:Asset) REQUIRE as.assetId IS UNIQUE'\n",
      "INFO:__main__:Created constraint: (l:Location)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:Location) REQUIRE (e.locationId) IS UNIQUE' has no effect. The index or constraint specified by 'CONSTRAINT locationId_Location_uniq FOR (e:Location) REQUIRE (e.locationId) IS UNIQUE' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE CONSTRAINT  IF NOT EXISTS FOR (l:Location) REQUIRE l.locationId IS UNIQUE'\n",
      "INFO:__main__:Created constraint: (s:ServiceRequest)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:ServiceRequest) REQUIRE (e.requestId) IS UNIQUE' has no effect. The index or constraint specified by 'CONSTRAINT requestId_ServiceRequest_uniq FOR (e:ServiceRequest) REQUIRE (e.requestId) IS UNIQUE' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE CONSTRAINT  IF NOT EXISTS FOR (s:ServiceRequest) REQUIRE s.requestId IS UNIQUE'\n",
      "INFO:__main__:Created constraint: (c:Country)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:Country) REQUIRE (e.country) IS UNIQUE' has no effect. The index or constraint specified by 'CONSTRAINT country_Country_uniq FOR (e:Country) REQUIRE (e.country) IS UNIQUE' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE CONSTRAINT  IF NOT EXISTS FOR (c:Country) REQUIRE c.country IS UNIQUE'\n",
      "INFO:__main__:Created constraint: (cu:Customer)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:Customer) REQUIRE (e.customer) IS UNIQUE' has no effect. The index or constraint specified by 'CONSTRAINT customer_Customer_uniq FOR (e:Customer) REQUIRE (e.customer) IS UNIQUE' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE CONSTRAINT  IF NOT EXISTS FOR (cu:Customer) REQUIRE cu.customer IS UNIQUE'\n",
      "WARNING:__main__:Constraint may already exist: {neo4j_code: Neo.ClientError.Schema.IndexAlreadyExists} {message: There already exists an index (:ServiceRequest {serviceClassificationId}). A constraint cannot be created until the index has been dropped.} {gql_status: 22N73} {gql_status_description: error: data exception - constraint conflicts with existing index. Constraint conflicts with already existing index '(:ServiceRequest {serviceClassificationId})'.}\n",
      "INFO:__main__:Created index: CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdYear)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE RANGE INDEX IF NOT EXISTS FOR (e:ServiceRequest) ON (e.createdYear)' has no effect. The index or constraint specified by 'RANGE INDEX index_91f78209 FOR (e:ServiceRequest) ON (e.createdYear)' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdYear)'\n",
      "INFO:__main__:Created index: CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.isCompleted)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE RANGE INDEX IF NOT EXISTS FOR (e:ServiceRequest) ON (e.isCompleted)' has no effect. The index or constraint specified by 'RANGE INDEX index_b84b7aaf FOR (e:ServiceRequest) ON (e.isCompleted)' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.isCompleted)'\n",
      "INFO:__main__:Created index: CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdMonth)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE RANGE INDEX IF NOT EXISTS FOR (e:ServiceRequest) ON (e.createdMonth)' has no effect. The index or constraint specified by 'RANGE INDEX index_f1f79818 FOR (e:ServiceRequest) ON (e.createdMonth)' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.createdMonth)'\n",
      "INFO:__main__:Created index: CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.sla)\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='00NA0', status_description=\"note: successful completion - index or constraint already exists. The command 'CREATE RANGE INDEX IF NOT EXISTS FOR (e:ServiceRequest) ON (e.sla)' has no effect. The index or constraint specified by 'RANGE INDEX index_1bc49cd0 FOR (e:ServiceRequest) ON (e.sla)' already exists.\", position=None, raw_classification='SCHEMA', classification=<NotificationClassification.SCHEMA: 'SCHEMA'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'SCHEMA', '_severity': 'INFORMATION', 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'CREATE INDEX IF NOT EXISTS FOR (s:ServiceRequest) ON (s.sla)'\n",
      "INFO:__main__:Loading 490557 Activity nodes from neo4j_data/activities.csv\n",
      "INFO:__main__:Loaded batch 1/25 for Activity\n",
      "INFO:__main__:Loaded batch 2/25 for Activity\n",
      "INFO:__main__:Loaded batch 3/25 for Activity\n",
      "INFO:__main__:Loaded batch 4/25 for Activity\n",
      "INFO:__main__:Loaded batch 5/25 for Activity\n",
      "INFO:__main__:Loaded batch 6/25 for Activity\n",
      "INFO:__main__:Loaded batch 7/25 for Activity\n",
      "INFO:__main__:Loaded batch 8/25 for Activity\n",
      "INFO:__main__:Loaded batch 9/25 for Activity\n",
      "INFO:__main__:Loaded batch 10/25 for Activity\n",
      "INFO:__main__:Loaded batch 11/25 for Activity\n",
      "INFO:__main__:Loaded batch 12/25 for Activity\n",
      "INFO:__main__:Loaded batch 13/25 for Activity\n",
      "INFO:__main__:Loaded batch 14/25 for Activity\n",
      "INFO:__main__:Loaded batch 15/25 for Activity\n",
      "INFO:__main__:Loaded batch 16/25 for Activity\n",
      "INFO:__main__:Loaded batch 17/25 for Activity\n",
      "INFO:__main__:Loaded batch 18/25 for Activity\n",
      "INFO:__main__:Loaded batch 19/25 for Activity\n",
      "INFO:__main__:Loaded batch 20/25 for Activity\n",
      "INFO:__main__:Loaded batch 21/25 for Activity\n",
      "INFO:__main__:Loaded batch 22/25 for Activity\n",
      "INFO:__main__:Loaded batch 23/25 for Activity\n",
      "INFO:__main__:Loaded batch 24/25 for Activity\n",
      "INFO:__main__:Loaded batch 25/25 for Activity\n",
      "INFO:__main__:Completed loading Activity nodes\n",
      "INFO:__main__:Loading 569239 Asset nodes from neo4j_data/assets.csv\n",
      "INFO:__main__:Loaded batch 1/29 for Asset\n",
      "INFO:__main__:Loaded batch 2/29 for Asset\n",
      "INFO:__main__:Loaded batch 3/29 for Asset\n",
      "INFO:__main__:Loaded batch 4/29 for Asset\n",
      "INFO:__main__:Loaded batch 5/29 for Asset\n",
      "INFO:__main__:Loaded batch 6/29 for Asset\n",
      "INFO:__main__:Loaded batch 7/29 for Asset\n",
      "INFO:__main__:Loaded batch 8/29 for Asset\n",
      "INFO:__main__:Loaded batch 9/29 for Asset\n",
      "INFO:__main__:Loaded batch 10/29 for Asset\n",
      "INFO:__main__:Loaded batch 11/29 for Asset\n",
      "INFO:__main__:Loaded batch 12/29 for Asset\n",
      "INFO:__main__:Loaded batch 13/29 for Asset\n",
      "INFO:__main__:Loaded batch 14/29 for Asset\n",
      "INFO:__main__:Loaded batch 15/29 for Asset\n",
      "INFO:__main__:Loaded batch 16/29 for Asset\n",
      "INFO:__main__:Loaded batch 17/29 for Asset\n",
      "INFO:__main__:Loaded batch 18/29 for Asset\n",
      "INFO:__main__:Loaded batch 19/29 for Asset\n",
      "INFO:__main__:Loaded batch 20/29 for Asset\n",
      "INFO:__main__:Loaded batch 21/29 for Asset\n",
      "INFO:__main__:Loaded batch 22/29 for Asset\n",
      "INFO:__main__:Loaded batch 23/29 for Asset\n",
      "INFO:__main__:Loaded batch 24/29 for Asset\n",
      "INFO:__main__:Loaded batch 25/29 for Asset\n",
      "INFO:__main__:Loaded batch 26/29 for Asset\n",
      "INFO:__main__:Loaded batch 27/29 for Asset\n",
      "INFO:__main__:Loaded batch 28/29 for Asset\n",
      "INFO:__main__:Loaded batch 29/29 for Asset\n",
      "INFO:__main__:Completed loading Asset nodes\n",
      "INFO:__main__:Loading 75 Country nodes from neo4j_data/countries.csv\n",
      "INFO:__main__:Loaded batch 1/1 for Country\n",
      "INFO:__main__:Completed loading Country nodes\n",
      "INFO:__main__:Loading 71 Customer nodes from neo4j_data/customers.csv\n",
      "INFO:__main__:Loaded batch 1/1 for Customer\n",
      "INFO:__main__:Completed loading Customer nodes\n",
      "INFO:__main__:Loading 48220 Location nodes from neo4j_data/location.csv\n",
      "INFO:__main__:Loaded batch 1/3 for Location\n",
      "INFO:__main__:Loaded batch 2/3 for Location\n",
      "INFO:__main__:Loaded batch 3/3 for Location\n",
      "INFO:__main__:Completed loading Location nodes\n",
      "INFO:__main__:Loading 597107 ServiceRequest nodes from neo4j_data/service_requests.csv\n",
      "INFO:__main__:Loaded batch 1/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 2/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 3/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 4/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 5/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 6/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 7/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 8/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 9/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 10/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 11/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 12/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 13/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 14/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 15/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 16/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 17/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 18/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 19/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 20/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 21/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 22/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 23/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 24/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 25/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 26/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 27/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 28/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 29/30 for ServiceRequest\n",
      "INFO:__main__:Loaded batch 30/30 for ServiceRequest\n",
      "INFO:__main__:Completed loading ServiceRequest nodes\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:LOADING RELATIONSHIPS\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:Loading 568927 LOCATED_AT relationships from neo4j_relationships/LOCATED_AT.csv\n",
      "INFO:__main__:Loaded batch 1/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 2/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 3/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 4/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 5/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 6/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 7/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 8/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 9/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 10/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 11/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 12/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 13/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 14/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 15/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 16/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 17/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 18/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 19/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 20/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 21/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 22/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 23/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 24/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 25/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 26/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 27/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 28/29 for LOCATED_AT\n",
      "INFO:__main__:Loaded batch 29/29 for LOCATED_AT\n",
      "INFO:__main__:Completed loading LOCATED_AT relationships\n",
      "INFO:__main__:Loading 586536 AT_LOCATION relationships from neo4j_relationships/AT_LOCATION.csv\n",
      "INFO:__main__:Loaded batch 1/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 2/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 3/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 4/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 5/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 6/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 7/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 8/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 9/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 10/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 11/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 12/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 13/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 14/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 15/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 16/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 17/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 18/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 19/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 20/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 21/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 22/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 23/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 24/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 25/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 26/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 27/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 28/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 29/30 for AT_LOCATION\n",
      "INFO:__main__:Loaded batch 30/30 for AT_LOCATION\n",
      "INFO:__main__:Completed loading AT_LOCATION relationships\n",
      "INFO:__main__:Loading 490557 HAS_ACTIVITY relationships from neo4j_relationships/HAS_ACTIVITY.csv\n",
      "INFO:__main__:Loaded batch 1/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 2/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 3/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 4/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 5/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 6/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 7/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 8/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 9/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 10/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 11/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 12/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 13/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 14/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 15/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 16/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 17/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 18/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 19/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 20/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 21/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 22/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 23/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 24/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Loaded batch 25/25 for HAS_ACTIVITY\n",
      "INFO:__main__:Completed loading HAS_ACTIVITY relationships\n",
      "INFO:__main__:Loading 237367 FOR_ASSET relationships from neo4j_relationships/FOR_ASSET.csv\n",
      "INFO:__main__:Loaded batch 1/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 2/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 3/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 4/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 5/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 6/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 7/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 8/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 9/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 10/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 11/12 for FOR_ASSET\n",
      "INFO:__main__:Loaded batch 12/12 for FOR_ASSET\n",
      "INFO:__main__:Completed loading FOR_ASSET relationships\n",
      "INFO:__main__:Loading 313 OPERATES_IN relationships from neo4j_relationships/OPERATES_IN.csv\n",
      "INFO:__main__:Loaded batch 1/1 for OPERATES_IN\n",
      "INFO:__main__:Completed loading OPERATES_IN relationships\n",
      "INFO:__main__:Loading 48220 RESIDES_AT relationships from neo4j_relationships/RESIDES_AT.csv\n",
      "INFO:__main__:Loaded batch 1/3 for RESIDES_AT\n",
      "INFO:__main__:Loaded batch 2/3 for RESIDES_AT\n",
      "INFO:__main__:Loaded batch 3/3 for RESIDES_AT\n",
      "INFO:__main__:Completed loading RESIDES_AT relationships\n",
      "INFO:__main__:Loading 568927 OWNS relationships from neo4j_relationships/OWNS.csv\n",
      "INFO:__main__:Loaded batch 1/29 for OWNS\n",
      "INFO:__main__:Loaded batch 2/29 for OWNS\n",
      "INFO:__main__:Loaded batch 3/29 for OWNS\n",
      "INFO:__main__:Loaded batch 4/29 for OWNS\n",
      "INFO:__main__:Loaded batch 5/29 for OWNS\n",
      "INFO:__main__:Loaded batch 6/29 for OWNS\n",
      "INFO:__main__:Loaded batch 7/29 for OWNS\n",
      "INFO:__main__:Loaded batch 8/29 for OWNS\n",
      "INFO:__main__:Loaded batch 9/29 for OWNS\n",
      "INFO:__main__:Loaded batch 10/29 for OWNS\n",
      "INFO:__main__:Loaded batch 11/29 for OWNS\n",
      "INFO:__main__:Loaded batch 12/29 for OWNS\n",
      "INFO:__main__:Loaded batch 13/29 for OWNS\n",
      "INFO:__main__:Loaded batch 14/29 for OWNS\n",
      "INFO:__main__:Loaded batch 15/29 for OWNS\n",
      "INFO:__main__:Loaded batch 16/29 for OWNS\n",
      "INFO:__main__:Loaded batch 17/29 for OWNS\n",
      "INFO:__main__:Loaded batch 18/29 for OWNS\n",
      "INFO:__main__:Loaded batch 19/29 for OWNS\n",
      "INFO:__main__:Loaded batch 20/29 for OWNS\n",
      "INFO:__main__:Loaded batch 21/29 for OWNS\n",
      "INFO:__main__:Loaded batch 22/29 for OWNS\n",
      "INFO:__main__:Loaded batch 23/29 for OWNS\n",
      "INFO:__main__:Loaded batch 24/29 for OWNS\n",
      "INFO:__main__:Loaded batch 25/29 for OWNS\n",
      "INFO:__main__:Loaded batch 26/29 for OWNS\n",
      "INFO:__main__:Loaded batch 27/29 for OWNS\n",
      "INFO:__main__:Loaded batch 28/29 for OWNS\n",
      "INFO:__main__:Loaded batch 29/29 for OWNS\n",
      "INFO:__main__:Completed loading OWNS relationships\n",
      "INFO:__main__:Loading 586535 CREATES relationships from neo4j_relationships/CREATES.csv\n",
      "INFO:__main__:Loaded batch 1/30 for CREATES\n",
      "INFO:__main__:Loaded batch 2/30 for CREATES\n",
      "INFO:__main__:Loaded batch 3/30 for CREATES\n",
      "INFO:__main__:Loaded batch 4/30 for CREATES\n",
      "INFO:__main__:Loaded batch 5/30 for CREATES\n",
      "INFO:__main__:Loaded batch 6/30 for CREATES\n",
      "INFO:__main__:Loaded batch 7/30 for CREATES\n",
      "INFO:__main__:Loaded batch 8/30 for CREATES\n",
      "INFO:__main__:Loaded batch 9/30 for CREATES\n",
      "INFO:__main__:Loaded batch 10/30 for CREATES\n",
      "INFO:__main__:Loaded batch 11/30 for CREATES\n",
      "INFO:__main__:Loaded batch 12/30 for CREATES\n",
      "INFO:__main__:Loaded batch 13/30 for CREATES\n",
      "INFO:__main__:Loaded batch 14/30 for CREATES\n",
      "INFO:__main__:Loaded batch 15/30 for CREATES\n",
      "INFO:__main__:Loaded batch 16/30 for CREATES\n",
      "INFO:__main__:Loaded batch 17/30 for CREATES\n",
      "INFO:__main__:Loaded batch 18/30 for CREATES\n",
      "INFO:__main__:Loaded batch 19/30 for CREATES\n",
      "INFO:__main__:Loaded batch 20/30 for CREATES\n",
      "INFO:__main__:Loaded batch 21/30 for CREATES\n",
      "INFO:__main__:Loaded batch 22/30 for CREATES\n",
      "INFO:__main__:Loaded batch 23/30 for CREATES\n",
      "INFO:__main__:Loaded batch 24/30 for CREATES\n",
      "INFO:__main__:Loaded batch 25/30 for CREATES\n",
      "INFO:__main__:Loaded batch 26/30 for CREATES\n",
      "INFO:__main__:Loaded batch 27/30 for CREATES\n",
      "INFO:__main__:Loaded batch 28/30 for CREATES\n",
      "INFO:__main__:Loaded batch 29/30 for CREATES\n",
      "INFO:__main__:Loaded batch 30/30 for CREATES\n",
      "INFO:__main__:Completed loading CREATES relationships\n",
      "INFO:__main__:Loading 48220 IN relationships from neo4j_relationships/IN.csv\n",
      "INFO:__main__:Loaded batch 1/3 for IN\n",
      "INFO:__main__:Loaded batch 2/3 for IN\n",
      "INFO:__main__:Loaded batch 3/3 for IN\n",
      "INFO:__main__:Completed loading IN relationships\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:VERIFYING NODE AND RELATIONSHP CREATION.\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:Activity nodes: 491469\n",
      "INFO:__main__:Asset nodes: 615152\n",
      "INFO:__main__:Country nodes: 75\n",
      "INFO:__main__:Customer nodes: 77\n",
      "INFO:__main__:Location nodes: 48359\n",
      "INFO:__main__:ServiceRequest nodes: 517015\n",
      "INFO:__main__:LOCATES_AT relationships: 155704\n",
      "INFO:__main__:LOCATED_AT relationships: 249339\n",
      "INFO:__main__:HAPPENS_AT relationships: 442508\n",
      "INFO:__main__:AT_LOCATION relationships: 613402\n",
      "INFO:__main__:HAS_ACTIVITY relationships: 516818\n",
      "INFO:__main__:REALTED_TO relationships: 170869\n",
      "INFO:__main__:FOR_ASSET relationships: 264016\n",
      "INFO:__main__:OPERATES_IN relationships: 330\n",
      "INFO:__main__:CREATES relationships: 593389\n",
      "INFO:__main__:RESIDES_AT relationships: 48463\n",
      "INFO:__main__:OWNS relationships: 347201\n",
      "INFO:__main__:IN relationships: 48359\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:DATA MIGRATION SUCCESSFUL!\n",
      "INFO:__main__:==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    dataLoader = DataLoader('config.ini')\n",
    "    dataLoader.executor()\n",
    "\n",
    "except NameError:\n",
    "    logger.warning(\"The DataLoader class is not defined. Please ensure it is defined correctly.\")\n",
    "\n",
    "try:\n",
    "    dataMigrator = DataMigrator('config.ini')\n",
    "    dataMigrator.executor()\n",
    "\n",
    "except NameError:\n",
    "    logger.warning(\"The DataMigrator class is not defined. Please ensure it is defined correctly.\")\n",
    "\n",
    "\n",
    "#to-do:\n",
    "# --> define paths for csvs in config.ini -- cosmetic, later\n",
    "# --> filter features from 'final_data' -- done\n",
    "# --> create csvs/dfs for neo4j migration -- done\n",
    "# --> migration!! -- on going\n",
    "\n",
    "# Data_migrator('config.ini', target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO:__main__:==================================================\n",
    "# INFO:__main__:LOADING DATA\n",
    "# INFO:__main__:==================================================\n",
    "# INFO:__main__: Downloaded 467196 rows from 'v_requests', 508856 rows from 'v_assets', and 482885 rows from 'v_request_with_activities'.\n",
    "# INFO:__main__:Data exported to ./fetched_data\n",
    "# INFO:__main__:Helper CSV files loaded successfully.\n",
    "# INFO:__main__:Node and Property data prepared!\n",
    "# INFO:__main__:Data for migration to Neo4J is saved on path: ./neo4j_data and ready to be imported!\n",
    "# INFO:__main__:Relationships created and saved to path: ./neo4j_relationships\n",
    "# INFO:__main__:==================================================\n",
    "# INFO:__main__:DATA LOADING SUCCESSFUL!\n",
    "# INFO:__main__:=================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304260d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>locationPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGB112695</td>\n",
       "      <td>National Exhibition Centre / Centre Core / Lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUS351642</td>\n",
       "      <td>US, CO, CASTLE ROCK / 5454 GARTON RD - CRBC03 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUS409154</td>\n",
       "      <td>US,TX,Texarkana / ALT-T CHRISTUS Pine Street -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LUS226145</td>\n",
       "      <td>US,TX,Texarkana / ALT-T St. Michael Acute Hosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LUS182335</td>\n",
       "      <td>US, GA, Atlanta / Store Support Ctr - Bldg D /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48215</th>\n",
       "      <td>LUS495445</td>\n",
       "      <td>US, PA, Malvern / Malvern-M1 / Floor 2 / M1-2005A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48216</th>\n",
       "      <td>LUS232013</td>\n",
       "      <td>US,TX,Tyler / TMF-T (Main Bldg) Mother Frances...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48217</th>\n",
       "      <td>LUS375530</td>\n",
       "      <td>US, SC, Myrtle Beach / 3694 Palmeto Point Blv_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48218</th>\n",
       "      <td>LUS264832</td>\n",
       "      <td>US, CA, Gorman / Bailey Sub / 1st Floor / Buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48219</th>\n",
       "      <td>LUS323741</td>\n",
       "      <td>US, OH, Cleveland / 9601 Chester Avenue / Floo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48220 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      locationId                                       locationPath\n",
       "0      LGB112695  National Exhibition Centre / Centre Core / Lev...\n",
       "1      LUS351642  US, CO, CASTLE ROCK / 5454 GARTON RD - CRBC03 ...\n",
       "2      LUS409154  US,TX,Texarkana / ALT-T CHRISTUS Pine Street -...\n",
       "3      LUS226145  US,TX,Texarkana / ALT-T St. Michael Acute Hosp...\n",
       "4      LUS182335  US, GA, Atlanta / Store Support Ctr - Bldg D /...\n",
       "...          ...                                                ...\n",
       "48215  LUS495445  US, PA, Malvern / Malvern-M1 / Floor 2 / M1-2005A\n",
       "48216  LUS232013  US,TX,Tyler / TMF-T (Main Bldg) Mother Frances...\n",
       "48217  LUS375530  US, SC, Myrtle Beach / 3694 Palmeto Point Blv_...\n",
       "48218  LUS264832  US, CA, Gorman / Bailey Sub / 1st Floor / Buil...\n",
       "48219  LUS323741  US, OH, Cleveland / 9601 Chester Avenue / Floo...\n",
       "\n",
       "[48220 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'_\\xe1\\xc3{*g\\xab\\xd8\\x88\\xa2\\x85\\xb0Z\\xed_\\xc1\\x97*\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04', b'\\xc0\\x01\\xc0\\x02\\xc0\\x03\\xc0\\x04\\xc0\\x05\\xc0\\x06\\xc0\\x07\\xc0\\x08\\xc0\\t', b\"\\xc0\\x0b\\xc0\\x0c\\xc0\\r\\xc0\\x0e\\xc0\\x0f\\xc0\\x10\\xc0\\x11\\xc0\\x12\\xc0\\x13\\xc0\\x14\\xc0\\x15\\xc0\\x16\\xc0\\x17\\xc0\\x18\\xc0\\x19\\xc0#\\xc0$\\xc0%\\xc0&\\xc0'\\xc0(\\xc0)\\xc0*\\xc0+\\xc0,\\xc0-\\xc0.\\xc0/\\xc00\\xc01\\xc02\\xc0r\\xc0s\\xc0t\\xc0u\\xc0v\\xc0w\\xc0x\\xc0y\\xc0z\\xc0{\\xc0|\\xc0}\\xc0~\\xc0\\x7f\\xc0\\x80\\xc0\\x81\\xc0\\x82\\xc0\\x83\\xc0\\x84\\xc0\\x85\\xc0\\x86\\xc0\\x87\\xc0\\x88\\xc0\\x89\\xc0\\x8a\\xc0\\x8b\\xc0\\x8c\\xc0\\x8d\\xc0\\x8e\\xc0\\x8f\\xc0\\x90\\xc0\\x91\\xc0\\x92\\xc0\\x93\\xc0\\x94\\xc0\\x95\\xc0\\x96\\xc0\\x97\\xc0\\x98\\xc0\\x99\\xc0\\x9a\\xc0\\x9b\\xcc\\xa8\\xcc\\xa9\\xcc\\xaa\\xcc\\xab\\xcc\\xac\\xcc\\xad\\xcc\\xae\\x02\\x00\\x01\\x00J\\x00\\n\\x00\\n\\x00\\x08\\x00\\x17\\x00\\x19\\x00\\x18\\x00\\x16\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\r\\x000\"]\n",
      "Bad pipe message: %s [b'\\x99\\x07\\xf3\\xd6\\xa2\\xbd\\xec9\\x8f\\xd5\\x00D\\x14$\\x16f\\x86z\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88']\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv('./neo4j_data/location.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = GraphDatabase.driver('neo4j+s://ad1b8c29.production-orch-0451.neo4j.io', auth=('neo4j', 'cDUOCN-88-eJaUlnuR3WRCwC3dij6y9Spnl4wwF1nQM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75396845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           customer\n",
      "0           DIRECTV\n",
      "1   Christus Health\n",
      "2   Home Depot Corp\n",
      "3        S&P Global\n",
      "4             Sidel\n",
      "..              ...\n",
      "72        lululemon\n",
      "73        CoreWeave\n",
      "74      EXL Service\n",
      "75         Vodafone\n",
      "76         Interpol\n",
      "\n",
      "[77 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# with driver.session() as session:\n",
    "#     result = session.run(\"\"\"\n",
    "#         MATCH (cu:Customer)\n",
    "#         RETURN cu.customer AS customer\n",
    "#     \"\"\")\n",
    "    \n",
    "#     # Convert to DataFrame\n",
    "#     customers_df = pd.DataFrame([record.data() for record in result])\n",
    "#     print(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd78da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>McGraw Hill Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Baptist Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>J&amp;J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>KeyBank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Cohesity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ericsson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer\n",
       "45  McGraw Hill Education\n",
       "46         Baptist Health\n",
       "47                    J&J\n",
       "48                KeyBank\n",
       "49               Cohesity\n",
       "50               Ericsson"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 339, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 345, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "Bad pipe message: %s [b'L\\x86w\\xa3\\xb1\\xab\\x12W\\x9c)\\xecp\\xc9\\x842\\xdc@\\x0b\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03']\n",
      "Bad pipe message: %s [b'\\xcaT\\xd0\\x8b\\x9fO\\x1d\\x18P\\\\,\\xbe\\x8b\\x8b.1\\xcf\\xb7\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00', b'\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x00']\n",
      "Bad pipe message: %s [b':\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00']\n",
      "Bad pipe message: %s [b\"\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04\\x13\\x05\\xc0\\x01\\xc0\\x02\\xc0\\x03\\xc0\\x04\\xc0\\x05\\xc0\\x06\\xc0\\x07\\xc0\\x08\\xc0\\t\\xc0\\n\\xc0\\x0b\\xc0\\x0c\\xc0\\r\\xc0\\x0e\\xc0\\x0f\\xc0\\x10\\xc0\\x11\\xc0\\x12\\xc0\\x13\\xc0\\x14\\xc0\\x15\\xc0\\x16\\xc0\\x17\\xc0\\x18\\xc0\\x19\\xc0#\\xc0$\\xc0%\\xc0&\\xc0'\\xc0(\\xc0)\\xc0*\\xc0+\\xc0,\\xc0-\\xc0.\\xc0/\\xc00\\xc01\\xc02\\xc0r\\xc0s\\xc0t\"]\n",
      "Bad pipe message: %s [b'\\t\\x06\\xa5\\xb5ih\\xf3\\x1eo0L\\xde\\xc6\\xa9\\xbeJ\\xb79\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00', b\"\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04\\x13\\x05\\xc0\\x01\\xc0\\x02\\xc0\\x03\\xc0\\x04\\xc0\\x05\\xc0\\x06\\xc0\\x07\\xc0\\x08\\xc0\\t\\xc0\\n\\xc0\\x0b\\xc0\\x0c\\xc0\\r\\xc0\\x0e\\xc0\\x0f\\xc0\\x10\\xc0\\x11\\xc0\\x12\\xc0\\x13\\xc0\\x14\\xc0\\x15\\xc0\\x16\\xc0\\x17\\xc0\\x18\\xc0\\x19\\xc0#\\xc0$\\xc0%\\xc0&\\xc0'\\xc0(\\xc0)\\xc0*\\xc0+\\xc0,\\xc0-\\xc0.\\xc0/\\xc00\\xc01\\xc02\\xc0r\\xc0s\\xc0t\\xc0u\\xc0v\\xc0w\\xc0x\\xc0y\\xc0z\\xc0{\\xc0|\\xc0}\\xc0~\\xc0\\x7f\\xc0\\x80\\xc0\\x81\\xc0\\x82\\xc0\\x83\\xc0\\x84\\xc0\\x85\\xc0\\x86\\xc0\\x87\\xc0\\x88\\xc0\\x89\\xc0\\x8a\\xc0\\x8b\\xc0\\x8c\\xc0\\x8d\\xc0\\x8e\\xc0\\x8f\\xc0\\x90\\xc0\\x91\\xc0\\x92\\xc0\\x93\\xc0\\x94\\xc0\\x95\\xc0\\x96\\xc0\\x97\\xc0\\x98\\xc0\\x99\\xc0\"]\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 663, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/SChauhan17/Desktop/projects/data_ingestion_pipeline/data_injestion/lib/python3.13/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n"
     ]
    }
   ],
   "source": [
    "# customers_df[~customers_df['customer'].isin(neo4j_cust['customer'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91b233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_injestion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
